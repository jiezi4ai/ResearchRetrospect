{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Retrospect PoC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jiezi/Code/GitHub/ResearchRetrospect/wip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "print(parent_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_reorder_dict(input_dict, keys_to_keep):\n",
    "    \"\"\"filter and re-order keys of dict\"\"\"\n",
    "    return {key: input_dict[key] for key in keys_to_keep if key in input_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get paper metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 09:54:53,357 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=From+Local+to+Global%3A+A+Graph+RAG+Approach+to+Query-Focused+Summarization&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=3 \"HTTP/1.1 429 \"\n",
      "2025-03-04 09:55:24,898 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=From+Local+to+Global%3A+A+Graph+RAG+Approach+to+Query-Focused+Summarization&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=3 \"HTTP/1.1 429 \"\n",
      "2025-03-04 09:56:03,198 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=From+Local+to+Global%3A+A+Graph+RAG+Approach+to+Query-Focused+Summarization&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=3 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paperId': 'c1799bf28d1ae93e1631be5b59196ee1e568f538', 'externalIds': {'ArXiv': '2404.16130', 'DBLP': 'journals/corr/abs-2404-16130', 'DOI': '10.48550/arXiv.2404.16130', 'CorpusId': 269363075}, 'corpusId': 269363075, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 'url': 'https://www.semanticscholar.org/paper/c1799bf28d1ae93e1631be5b59196ee1e568f538', 'title': 'From Local to Global: A Graph RAG Approach to Query-Focused Summarization', 'abstract': 'The use of retrieval-augmented generation (RAG) to retrieve relevant information from an external knowledge source enables large language models (LLMs) to answer questions over private and/or previously unseen document collections. However, RAG fails on global questions directed at an entire text corpus, such as\"What are the main themes in the dataset?\", since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. Prior QFS methods, meanwhile, do not scale to the quantities of text indexed by typical RAG systems. To combine the strengths of these contrasting methods, we propose GraphRAG, a graph-based approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text. Our approach uses an LLM to build a graph index in two stages: first, to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user. For a class of global sensemaking questions over datasets in the 1 million token range, we show that GraphRAG leads to substantial improvements over a conventional RAG baseline for both the comprehensiveness and diversity of generated answers.', 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 57, 'citationCount': 185, 'influentialCitationCount': 30, 'isOpenAccess': False, 'openAccessPdf': None, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle'], 'publicationDate': '2024-04-24', 'journal': {'name': 'ArXiv', 'volume': 'abs/2404.16130'}, 'citationStyles': {'bibtex': '@Article{Edge2024FromLT,\\n author = {Darren Edge and Ha Trinh and Newman Cheng and Joshua Bradley and Alex Chao and Apurva Mody and Steven Truitt and Jonathan Larson},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {From Local to Global: A Graph RAG Approach to Query-Focused Summarization},\\n volume = {abs/2404.16130},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2298275009', 'name': 'Darren Edge'}, {'authorId': '2213073417', 'name': 'Ha Trinh'}, {'authorId': '2298273973', 'name': 'Newman Cheng'}, {'authorId': '2298275805', 'name': 'Joshua Bradley'}, {'authorId': '2298274563', 'name': 'Alex Chao'}, {'authorId': '2210994342', 'name': 'Apurva Mody'}, {'authorId': '2298273810', 'name': 'Steven Truitt'}, {'authorId': '2298278846', 'name': 'Jonathan Larson'}]}\n"
     ]
    }
   ],
   "source": [
    "from apis.semanticscholar_tool import SemanticScholarKit\n",
    "s2 = SemanticScholarKit()\n",
    "paper_info = s2.search_paper_by_keywords(query=title, limit=3)\n",
    "paper_metadata = paper_info[0]\n",
    "print(paper_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 09:57:16,114 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/c1799bf28d1ae93e1631be5b59196ee1e568f538/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "{'intents': ['methodology'], 'isInfluential': False, 'contexts': ['These include using LLMs for knowledge graph creation (Tra-janoska et al., 2023) and completion (Yao et al., 2023), as well as for the extraction of causal graphs (Ban et al., 2023; Zhang et al., 2024) from source texts.'], 'contextsWithIntent': [{'context': 'These include using LLMs for knowledge graph creation (Tra-janoska et al., 2023) and completion (Yao et al., 2023), as well as for the extraction of causal graphs (Ban et al., 2023; Zhang et al., 2024) from source texts.', 'intents': ['methodology']}], 'citedPaper': {'paperId': '0504c5d96ebf7be01e2b622ff3a4bf155f2b0a41', 'externalIds': {'DBLP': 'journals/corr/abs-2402-15301', 'ArXiv': '2402.15301', 'DOI': '10.48550/arXiv.2402.15301', 'CorpusId': 267897516}, 'corpusId': 267897516, 'publicationVenue': {'id': '1901e811-ee72-4b20-8f7e-de08cd395a10', 'name': 'arXiv.org', 'alternate_names': ['ArXiv'], 'issn': '2331-8422', 'url': 'https://arxiv.org'}, 'url': 'https://www.semanticscholar.org/paper/0504c5d96ebf7be01e2b622ff3a4bf155f2b0a41', 'title': 'Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models', 'abstract': \"Causal graph recovery is traditionally done using statistical estimation-based methods or based on individual's knowledge about variables of interests. They often suffer from data collection biases and limitations of individuals' knowledge. The advance of large language models (LLMs) provides opportunities to address these problems. We propose a novel method that leverages LLMs to deduce causal relationships in general causal graph recovery tasks. This method leverages knowledge compressed in LLMs and knowledge LLMs extracted from scientific publication database as well as experiment data about factors of interest to achieve this goal. Our method gives a prompting strategy to extract associational relationships among those factors and a mechanism to perform causality verification for these associations. Comparing to other LLM-based methods that directly instruct LLMs to do the highly complex causal reasoning, our method shows clear advantage on causal graph quality on benchmark datasets. More importantly, as causality among some factors may change as new research results emerge, our method show sensitivity to new evidence in the literature and can provide useful information for updating causal graphs accordingly.\", 'venue': 'arXiv.org', 'year': 2024, 'referenceCount': 77, 'citationCount': 5, 'influentialCitationCount': 0, 'isOpenAccess': False, 'openAccessPdf': None, 'fieldsOfStudy': ['Computer Science', 'Mathematics'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle'], 'publicationDate': '2024-02-23', 'journal': {'volume': 'abs/2402.15301', 'name': 'ArXiv'}, 'citationStyles': {'bibtex': '@Article{Zhang2024CausalGD,\\n author = {Yuzhe Zhang and Yipeng Zhang and Yidong Gan and Lina Yao and Chen Wang},\\n booktitle = {arXiv.org},\\n journal = {ArXiv},\\n title = {Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models},\\n volume = {abs/2402.15301},\\n year = {2024}\\n}\\n'}, 'authors': [{'authorId': '2258602359', 'name': 'Yuzhe Zhang'}, {'authorId': '2286591780', 'name': 'Yipeng Zhang'}, {'authorId': '2286307576', 'name': 'Yidong Gan'}, {'authorId': '2258412350', 'name': 'Lina Yao'}, {'authorId': '2286410001', 'name': 'Chen Wang'}]}}\n"
     ]
    }
   ],
   "source": [
    "paper_references_info = s2.get_semanticscholar_references(paper_id=paper_id)\n",
    "print(len(paper_references_info))\n",
    "print(paper_references_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 09:58:06,306 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/c1799bf28d1ae93e1631be5b59196ee1e568f538/citations?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "{'contexts': ['GraphRAG [7] proposes a RAG pipeline on a set of text chunks that are connected based on their semantic similarities.'], 'contextsWithIntent': [{'context': 'GraphRAG [7] proposes a RAG pipeline on a set of text chunks that are connected based on their semantic similarities.', 'intents': []}], 'isInfluential': False, 'intents': [], 'citingPaper': {'paperId': 'ff18932102fd45fffd421410bff03c62447934c8', 'externalIds': {'ArXiv': '2502.21087', 'CorpusId': 276724735}, 'corpusId': 276724735, 'publicationVenue': None, 'url': 'https://www.semanticscholar.org/paper/ff18932102fd45fffd421410bff03c62447934c8', 'title': 'PASemiQA: Plan-Assisted Agent for Question Answering on Semi-Structured Data with Text and Relational Information', 'abstract': 'Large language models (LLMs) have shown impressive abilities in answering questions across various domains, but they often encounter hallucination issues on questions that require professional and up-to-date knowledge. To address this limitation, retrieval-augmented generation (RAG) techniques have been proposed, which retrieve relevant information from external sources to inform their responses. However, existing RAG methods typically focus on a single type of external data, such as vectorized text database or knowledge graphs, and cannot well handle real-world questions on semi-structured data containing both text and relational information. To bridge this gap, we introduce PASemiQA, a novel approach that jointly leverages text and relational information in semi-structured data to answer questions. PASemiQA first generates a plan to identify relevant text and relational information to answer the question in semi-structured data, and then uses an LLM agent to traverse the semi-structured data and extract necessary information. Our empirical results demonstrate the effectiveness of PASemiQA across different semi-structured datasets from various domains, showcasing its potential to improve the accuracy and reliability of question answering systems on semi-structured data.', 'venue': '', 'year': 2025, 'referenceCount': 24, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': False, 'openAccessPdf': None, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': None, 'publicationDate': '2025-02-28', 'journal': None, 'citationStyles': {'bibtex': '@Inproceedings{Yang2025PASemiQAPA,\\n author = {Hansi Yang and Qi Zhang and Wei Jiang and Jianguo Li},\\n title = {PASemiQA: Plan-Assisted Agent for Question Answering on Semi-Structured Data with Text and Relational Information},\\n year = {2025}\\n}\\n'}, 'authors': [{'authorId': None, 'name': 'Hansi Yang'}, {'authorId': None, 'name': 'Qi Zhang'}, {'authorId': None, 'name': 'Wei Jiang'}, {'authorId': None, 'name': 'Jianguo Li'}]}}\n"
     ]
    }
   ],
   "source": [
    "paper_citedby_info = s2.get_semanticscholar_citedby(paper_id=paper_id)\n",
    "print(len(paper_citedby_info))\n",
    "print(paper_citedby_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 10:01:21,638 - INFO - HTTP Request: POST https://api.semanticscholar.org/recommendations/v1/papers/?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&limit=100 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "{'paperId': '1a454582d3b3aaa6c6cd5b2be075958d13423f78', 'externalIds': {'ArXiv': '2502.11371', 'CorpusId': 276408622}, 'corpusId': 276408622, 'publicationVenue': None, 'url': 'https://www.semanticscholar.org/paper/1a454582d3b3aaa6c6cd5b2be075958d13423f78', 'title': 'RAG vs. GraphRAG: A Systematic Evaluation and Key Insights', 'abstract': 'Retrieval-Augmented Generation (RAG) enhances the performance of LLMs across various tasks by retrieving relevant information from external sources, particularly on text-based data. For structured data, such as knowledge graphs, GraphRAG has been widely used to retrieve relevant information. However, recent studies have revealed that structuring implicit knowledge from text into graphs can benefit certain tasks, extending the application of GraphRAG from graph data to general text-based data. Despite their successful extensions, most applications of GraphRAG for text data have been designed for specific tasks and datasets, lacking a systematic evaluation and comparison between RAG and GraphRAG on widely used text-based benchmarks. In this paper, we systematically evaluate RAG and GraphRAG on well-established benchmark tasks, such as Question Answering and Query-based Summarization. Our results highlight the distinct strengths of RAG and GraphRAG across different tasks and evaluation perspectives. Inspired by these observations, we investigate strategies to integrate their strengths to improve downstream tasks. Additionally, we provide an in-depth discussion of the shortcomings of current GraphRAG approaches and outline directions for future research.', 'venue': '', 'year': 2025, 'referenceCount': 46, 'citationCount': 0, 'influentialCitationCount': 0, 'isOpenAccess': False, 'openAccessPdf': None, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': None, 'publicationDate': '2025-02-17', 'journal': None, 'citationStyles': {'bibtex': '@Inproceedings{Han2025RAGVG,\\n author = {Haoyu Han and Harry Shomer and Yu Wang and Yongjia Lei and Kai Guo and Zhigang Hua and Bo Long and Hui Liu and Jiliang Tang},\\n title = {RAG vs. GraphRAG: A Systematic Evaluation and Key Insights},\\n year = {2025}\\n}\\n'}, 'authors': [{'authorId': '2049039664', 'name': 'Haoyu Han'}, {'authorId': '2220302956', 'name': 'Harry Shomer'}, {'authorId': '2346107355', 'name': 'Yu Wang'}, {'authorId': '2338562947', 'name': 'Yongjia Lei'}, {'authorId': '2338271219', 'name': 'Kai Guo'}, {'authorId': '2293482433', 'name': 'Zhigang Hua'}, {'authorId': '2338267824', 'name': 'Bo Long'}, {'authorId': '2345866507', 'name': 'Hui Liu'}, {'authorId': '2330147642', 'name': 'Jiliang Tang'}]}\n"
     ]
    }
   ],
   "source": [
    "paper_recommended_info = s2.find_recommendations(positive_paper_ids=[paper_id])\n",
    "print(len(paper_recommended_info))\n",
    "print(paper_recommended_info[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Key Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on References and Citedby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- s2 marked as inflential\n",
    "- citing more than once\n",
    "- citing paper inflential\n",
    "- citing paper abstract close to current paper\n",
    "- citing paper share authors with current paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.embedding_models import gemini_embedding_async, semantic_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'authorId': '2298275009', 'name': 'Darren Edge'},\n",
       "  {'authorId': '2213073417', 'name': 'Ha Trinh'},\n",
       "  {'authorId': '2298273973', 'name': 'Newman Cheng'},\n",
       "  {'authorId': '2298275805', 'name': 'Joshua Bradley'},\n",
       "  {'authorId': '2298274563', 'name': 'Alex Chao'},\n",
       "  {'authorId': '2210994342', 'name': 'Apurva Mody'},\n",
       "  {'authorId': '2298273810', 'name': 'Steven Truitt'},\n",
       "  {'authorId': '2298278846', 'name': 'Jonathan Larson'}],\n",
       " 'From Local to Global: A Graph RAG Approach to Query-Focused Summarization',\n",
       " 'The use of retrieval-augmented generation (RAG) to retrieve relevant information from an external knowledge source enables large language models (LLMs) to answer questions over private and/or previously unseen document collections. However, RAG fails on global questions directed at an entire text corpus, such as\"What are the main themes in the dataset?\", since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. Prior QFS methods, meanwhile, do not scale to the quantities of text indexed by typical RAG systems. To combine the strengths of these contrasting methods, we propose GraphRAG, a graph-based approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text. Our approach uses an LLM to build a graph index in two stages: first, to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user. For a class of global sensemaking questions over datasets in the 1 million token range, we show that GraphRAG leads to substantial improvements over a conventional RAG baseline for both the comprehensiveness and diversity of generated answers.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_metadata['authors'], paper_metadata['title'], paper_metadata['abstract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get citing paper metadata\n",
    "citing_info_keys = ['isInfluential', 'intents', 'contexts']\n",
    "paper_metadata_keys = ['title', 'abstract', 'citationCount', 'influentialCitationCount', 'authors', 'publicationDate', 'year']\n",
    "\n",
    "citing_metadata_lst = []\n",
    "for item in paper_references_info:\n",
    "    citing_info = filter_and_reorder_dict(item, citing_info_keys)\n",
    "\n",
    "    citing_paper_info = item.get('citedPaper', {})\n",
    "    if citing_paper_info and citing_paper_info != {}:\n",
    "        citing_paper_metadata = filter_and_reorder_dict(citing_paper_info, paper_metadata_keys)\n",
    "        citing_metadata = {**citing_paper_metadata, **citing_info}\n",
    "        citing_metadata_lst.append(citing_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'isInfluential': False,\n",
       " 'intents': ['background'],\n",
       " 'contexts': ['In terms of open-source software, a variety a graph databases are supported by both the LangChain (LangChain, 2024) and LlamaIndex (LlamaIndex, 2024) libraries, while a more general class of graph-based RAG applications is also emerging, including systems that can create and reason over knowledge graphs in both Neo4J (NaLLM, Neo4J, 2024) and Nebula-Graph (GraphRAG, NebulaGraph, 2024) formats.',\n",
       "  'LLMs have been shown to be good evaluators of natural language generation, achieving state-of-the-art or competitive results compared against human judgements (Wang et al., 2023a; Zheng et al., 2024).',\n",
       "  'In terms of open-source software, a variety a graph databases are supported by both the LangChain (LangChain, 2024) and LlamaIndex (LlamaIndex, 2024) libraries, while a more general class of graph-based RAG applications is also emerging, including systems that can create and reason over knowledge…']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citing_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get citing paper abstracts\n",
    "abstracts = []\n",
    "for item in citing_metadata_lst:\n",
    "    abstracts.append(item.get('abstract') if item.get('abstract') else 'NAN')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate abstract similarity\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY_1')\n",
    "gemini_model_name = \"models/text-embedding-004\"\n",
    "texts = [paper_metadata['abstract']] + abstracts\n",
    "n_concurrent = 5\n",
    "embeds = await gemini_embedding_async(gemini_api_key, gemini_model_name, texts, n_concurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "similarity_matrix = semantic_similarity_matrix(embeds[0], embeds[1:])\n",
    "similarity_matrix = np.array(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_similarity_scores = similarity_matrix[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(citing_metadata_lst) == len(abstracts_similarity_scores)\n",
    "for idx, item in enumerate(citing_metadata_lst):\n",
    "    item['sim_socre'] = abstracts_similarity_scores[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([1,2,3]) & set([2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering', 'abstract': \"Given a graph with textual attributes, we enable users to `chat with their graph': that is, to ask questions about the graph using a conversational interface. In response to a user's questions, our method provides textual replies and highlights the relevant parts of the graph. While existing works integrate large language models (LLMs) and graph neural networks (GNNs) in various ways, they mostly focus on either conventional graph tasks (such as node, edge, and graph classification), or on answering simple graph queries on small or synthetic graphs. In contrast, we develop a flexible question-answering framework targeting real-world textual graphs, applicable to multiple applications including scene graph understanding, common sense reasoning, and knowledge graph reasoning. Toward this goal, we first develop a Graph Question Answering (GraphQA) benchmark with data collected from different tasks. Then, we propose our G-Retriever method, introducing the first retrieval-augmented generation (RAG) approach for general textual graphs, which can be fine-tuned to enhance graph understanding via soft prompting. To resist hallucination and to allow for textual graphs that greatly exceed the LLM's context window size, G-Retriever performs RAG over a graph by formulating this task as a Prize-Collecting Steiner Tree optimization problem. Empirical evaluations show that our method outperforms baselines on textual graph tasks from multiple domains, scales well with larger graph sizes, and mitigates hallucination.~\\\\footnote{Our codes and datasets are available at: \\\\url{https://github.com/XiaoxinHe/G-Retriever}}\", 'citationCount': 44, 'influentialCitationCount': 6, 'authors': [{'authorId': '2283895736', 'name': 'Xiaoxin He'}, {'authorId': '46879986', 'name': 'Yijun Tian'}, {'authorId': '2283901770', 'name': 'Yifei Sun'}, {'authorId': '144539424', 'name': 'N. Chawla'}, {'authorId': '81634721', 'name': 'T. Laurent'}, {'authorId': '2265899558', 'name': 'Yann LeCun'}, {'authorId': '2279831845', 'name': 'Xavier Bresson'}, {'authorId': '2283877888', 'name': 'Bryan Hooi'}], 'publicationDate': '2024-02-12', 'year': 2024, 'isInfluential': False, 'intents': ['background'], 'contexts': ['…advanced RAG (Gao et al., 2023) where the index is a knowledge graph (KAPING, Baek et al., 2023), where subsets of the graph structure (G-Retriever, He et al., 2024) or derived graph metrics (Graph-ToolFormer, Zhang, 2023) are the objects of enquiry, where narrative outputs are strongly grounded…'], 'sim_socre': 0.7763859910362734}\n",
      "{'title': 'RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval', 'abstract': 'Retrieval-augmented language models can better adapt to changes in world state and incorporate long-tail knowledge. However, most existing methods retrieve only short contiguous chunks from a retrieval corpus, limiting holistic understanding of the overall document context. We introduce the novel approach of recursively embedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization from the bottom up. At inference time, our RAPTOR model retrieves from this tree, integrating information across lengthy documents at different levels of abstraction. Controlled experiments show that retrieval with recursive summaries offers significant improvements over traditional retrieval-augmented LMs on several tasks. On question-answering tasks that involve complex, multi-step reasoning, we show state-of-the-art results; for example, by coupling RAPTOR retrieval with the use of GPT-4, we can improve the best performance on the QuALITY benchmark by 20% in absolute accuracy.', 'citationCount': 84, 'influentialCitationCount': 10, 'authors': [{'authorId': '47157377', 'name': 'Parth Sarthi'}, {'authorId': '2281944713', 'name': 'Salman Abdullah'}, {'authorId': '2281943586', 'name': 'Aditi Tuli'}, {'authorId': '2331325744', 'name': 'Shubh Khanna'}, {'authorId': '2281943701', 'name': 'Anna Goldie'}, {'authorId': '2262643057', 'name': 'Christopher D. Manning'}], 'publicationDate': '2024-01-31', 'year': 2024, 'isInfluential': False, 'intents': ['background'], 'contexts': ['…also bears resemblance to further approaches, such as generating a hierarchical index of text chunks by clustering the vectors of text embeddings (RAPTOR, Sarthi et al., 2024) or generating a “tree of clarifications” to answer multiple interpretations of ambiguous questions (Kim et al., 2023).'], 'sim_socre': 0.7503935955861576}\n",
      "{'title': 'MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries', 'abstract': 'Retrieval-augmented generation (RAG) augments large language models (LLM) by retrieving relevant knowledge, showing promising potential in mitigating LLM hallucinations and enhancing response quality, thereby facilitating the great adoption of LLMs in practice. However, we find that existing RAG systems are inadequate in answering multi-hop queries, which require retrieving and reasoning over multiple pieces of supporting evidence. Furthermore, to our knowledge, no existing RAG benchmarking dataset focuses on multi-hop queries. In this paper, we develop a novel dataset, MultiHop-RAG, which consists of a knowledge base, a large collection of multi-hop queries, their ground-truth answers, and the associated supporting evidence. We detail the procedure of building the dataset, utilizing an English news article dataset as the underlying RAG knowledge base. We demonstrate the benchmarking utility of MultiHop-RAG in two experiments. The first experiment compares different embedding models for retrieving evidence for multi-hop queries. In the second experiment, we examine the capabilities of various state-of-the-art LLMs, including GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop queries given the evidence. Both experiments reveal that existing RAG methods perform unsatisfactorily in retrieving and answering multi-hop queries. We hope MultiHop-RAG will be a valuable resource for the community in developing effective RAG systems, thereby facilitating greater adoption of LLMs in practice. The MultiHop-RAG and implemented RAG system is publicly available at https://github.com/yixuantt/MultiHop-RAG/.', 'citationCount': 50, 'influentialCitationCount': 3, 'authors': [{'authorId': '2260449655', 'name': 'Yixuan Tang'}, {'authorId': '2246043972', 'name': 'Yi Yang'}], 'publicationDate': '2024-01-27', 'year': 2024, 'isInfluential': False, 'intents': ['background', 'methodology'], 'contexts': ['Many benchmark datasets for open-domain question answering exist, including HotPotQA (Yang et al., 2018), MultiHop-RAG (Tang and Yang, 2024), and MT-Bench (Zheng et al., 2024).', 'Community summaries are generated in the following way: (Traag et al., 2019) over the MultiHop-RAG (Tang and Yang, 2024) dataset as indexed.', 'Benchmark dataset comprising news articles published from September 2013 to December 2023 in a range of categories, including entertainment, business, sports, technology, health, and science (MultiHop-RAG; Tang and Yang, 2024).'], 'sim_socre': 0.7513422383360343}\n",
      "{'title': 'Retrieval-Augmented Generation for Large Language Models: A Survey', 'abstract': \"Large Language Models (LLMs) showcase impressive capabilities but encounter challenges like hallucination, outdated knowledge, and non-transparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the generation, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval, the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces up-to-date evaluation framework and benchmark. At the end, this article delineates the challenges currently faced and points out prospective avenues for research and development.\", 'citationCount': 1045, 'influentialCitationCount': 61, 'authors': [{'authorId': '2280046531', 'name': 'Yunfan Gao'}, {'authorId': '2275320371', 'name': 'Yun Xiong'}, {'authorId': '2275341478', 'name': 'Xinyu Gao'}, {'authorId': '2275191447', 'name': 'Kangxiang Jia'}, {'authorId': '2275530552', 'name': 'Jinliu Pan'}, {'authorId': '2275171009', 'name': 'Yuxi Bi'}, {'authorId': '2276187454', 'name': 'Yi Dai'}, {'authorId': '2275540959', 'name': 'Jiawei Sun'}, {'authorId': '2258800561', 'name': 'Qianyu Guo'}, {'authorId': '2291409458', 'name': 'Meng Wang'}, {'authorId': '2256769434', 'name': 'Haofen Wang'}], 'publicationDate': '2023-12-18', 'year': 2023, 'isInfluential': False, 'intents': ['background', 'methodology'], 'contexts': ['Na ¨ ıve RAG approaches (Gao et al., 2023) do this by converting documents to text, splitting text into chunks, and embedding these chunks into a vector space in which similar positions represent similar semantics.', 'They also include forms of advanced RAG (Gao et al., 2023) where the index is a knowledge graph (KAPING, Baek et al., 2023), where subsets of the graph structure (G-Retriever, He et al., 2024) or derived graph metrics (Graph-ToolFormer, Zhang, 2023) are the objects of enquiry, where narrative…', 'Advanced RAG systems include pre-retrieval, retrieval, post-retrieval strategies designed to overcome the drawbacks of Na¨ıve RAG, while Modular RAG systems include patterns for iterative and dynamic cycles of interleaved retrieval and generation (Gao et al., 2023).'], 'sim_socre': 0.7477885829393699}\n",
      "{'title': 'FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction', 'abstract': 'Narrative construction is the process of representing disparate event information into a logical plot structure that models an end to end story. Intelligence analysis is an example of a domain that can benefit tremendously from narrative construction techniques, particularly in aiding analysts during the largely manual and costly process of synthesizing event information into comprehensive intelligence reports. Manual intelligence report generation is often prone to challenges such as integrating dynamic event information, writing fine-grained queries, and closing information gaps. This motivates the development of a system that retrieves and represents critical aspects of events in a form that aids in automatic generation of intelligence reports. We introduce a Retrieval Augmented Generation (RAG) approach to augment prompting of an autoregressive decoder by retrieving structured information asserted in a knowledge graph to generate targeted information based on a narrative plot model. We apply our approach to the problem of neural intelligence report generation and introduce FABULA, framework to augment intelligence analysis workflows using RAG. An analyst can use FABULA to query an Event Plot Graph (EPG) to retrieve relevant event plot points, which can be used to augment prompting of a Large Language Model (LLM) during intelligence report generation. Our evaluation studies show that the plot points included in the generated intelligence reports have high semantic relevance, high coherency, and low data redundancy.', 'citationCount': 8, 'influentialCitationCount': 0, 'authors': [{'authorId': '51092885', 'name': 'P. Ranade'}, {'authorId': '2269936199', 'name': 'Anupam Joshi'}], 'publicationDate': '2023-10-20', 'year': 2023, 'isInfluential': False, 'intents': ['background', 'methodology'], 'contexts': ['With the emergence of large language models (LLMs), we are already witnessing attempts to automate human-like sensemaking in complex domains like scientific discovery (Microsoft, 2023) and intelligence analysis (Ranade and Joshi, 2023), where sensemaking is defined as', '…the facts of retrieved subgraphs (SURGE, Kang et al., 2023), where retrieved event-plot sub-graphs are serialized using narrative templates (FABULA, Ranade and Joshi, 2023), and where the system supports both creation and traversal of text-relationship graphs for multi-hop question answering (Wang…'], 'sim_socre': 0.7156341090255252}\n",
      "{'title': 'Retrieval-Generation Synergy Augmented Large Language Models', 'abstract': 'Large language models augmented with task-relevant documents have demonstrated impressive performance on knowledge-intensive tasks. However, regarding how to obtain effective documents, the existing methods are mainly divided into two categories. One is to retrieve from an external knowledge base, and the other is to utilize large language models to generate documents. We propose an iterative retrieval-generation collaborative framework. It is not only able to leverage both parametric and non-parametric knowledge, but also helps to find the correct reasoning path through retrieval-generation interactions, which is very important for tasks that require multi-step reasoning. We conduct experiments on four question answering datasets, including single-hop QA and multi-hop QA tasks. Empirical results show that our method significantly improves the reasoning ability of large language models and outperforms previous baselines.', 'citationCount': 25, 'influentialCitationCount': 2, 'authors': [{'authorId': '51056532', 'name': 'Zhangyin Feng'}, {'authorId': '2674998', 'name': 'Xiaocheng Feng'}, {'authorId': '2258097320', 'name': 'Dezhi Zhao'}, {'authorId': '2257128653', 'name': 'Maojin Yang'}, {'authorId': '2257004102', 'name': 'Bing Qin'}], 'publicationDate': '2023-10-08', 'year': 2023, 'isInfluential': False, 'intents': ['background'], 'contexts': ['Other systems have also combined these concepts for multi-document summarization (CAiRE-COVID, Su et al., 2020) and multi-hop question answering (ITRG, Feng et al., 2023; IR-CoT, Trivedi et al., 2022; DSP, Khattab et al., 2022).'], 'sim_socre': 0.7289520402649842}\n",
      "{'title': 'RAGAs: Automated Evaluation of Retrieval Augmented Generation', 'abstract': 'We introduce RAGAs (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAGAs is available at [https://github.com/explodinggradients/ragas]. RAG systems are composed of a retrieval and an LLM based generation module. They provide LLMs with knowledge from a reference textual database, enabling them to act as a natural language layer between a user and textual databases, thus reducing the risk of hallucinations. Evaluating RAG architectures is challenging due to several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages faithfully, and the quality of the generation itself. With RAGAs, we introduce a suite of metrics that can evaluate these different dimensions without relying on ground truth human annotations. We posit that such a framework can contribute crucially to faster evaluation cycles of RAG architectures, which is especially important given the fast adoption of LLMs.', 'citationCount': 129, 'influentialCitationCount': 13, 'authors': [{'authorId': '2214583051', 'name': 'ES Shahul'}, {'authorId': '2248138289', 'name': 'Jithin James'}, {'authorId': '2258950306', 'name': 'Luis Espinosa Anke'}, {'authorId': '2265382', 'name': 'S. Schockaert'}], 'publicationDate': '2023-09-26', 'year': 2023, 'isInfluential': False, 'intents': ['background'], 'contexts': ['LLMs have also shown promise at evaluating the performance of conventional RAG systems, automatically evaluating qualities like context relevance, faithfulness, and answer relevance (RAGAS, Es et al., 2023).'], 'sim_socre': 0.7063862289689586}\n",
      "{'title': 'Knowledge Graph Prompting for Multi-Document Question Answering', 'abstract': \"The `pre-train, prompt, predict' paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or document structural relations. For graph traversal, we design an LLM-based graph traversal agent that navigates across nodes and gathers supporting passages assisting LLMs in MD-QA. The constructed graph serves as the global ruler that regulates the transitional space among passages and reduces retrieval latency. Concurrently, the graph traversal agent acts as a local navigator that gathers pertinent context to progressively approach the question and guarantee retrieval quality. Extensive experiments underscore the efficacy of KGP for MD-QA, signifying the potential of leveraging graphs in enhancing the prompt design and retrieval augmented generation for LLMs. Our code: https://github.com/YuWVandy/KG-LLM-MDQA.\", 'citationCount': 77, 'influentialCitationCount': 7, 'authors': [{'authorId': '2153607948', 'name': 'Yu Wang'}, {'authorId': '1793409', 'name': 'Nedim Lipka'}, {'authorId': '2066337266', 'name': 'Ryan A. Rossi'}, {'authorId': '2233085914', 'name': 'Alexa F. Siu'}, {'authorId': '2283147661', 'name': 'Ruiyi Zhang'}, {'authorId': '12524628', 'name': 'Tyler Derr'}], 'publicationDate': '2023-08-22', 'year': 2023, 'isInfluential': False, 'intents': ['methodology'], 'contexts': ['…subgraphs (SURGE, Kang et al., 2023), where retrieved event-plot sub-graphs are serialized using narrative templates (FABULA, Ranade and Joshi, 2023), and where the system supports both creation and traversal of text-relationship graphs for multi-hop question answering (Wang et al., 2023b).'], 'sim_socre': 0.7328248671652462}\n",
      "{'title': 'Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy', 'abstract': 'Large language models are powerful text processors and reasoners, but are still subject to limitations including outdated knowledge and hallucinations, which necessitates connecting them to the world. Retrieval-augmented large language models have raised extensive attention for grounding model generation on external knowledge. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to improve retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call Iter-RetGen, which synergizes retrieval and generation in an iterative manner. A model output shows what might be needed to finish a task, and thus provides an informative context for retrieving more relevant knowledge which in turn helps generate a better output in the next iteration. Compared with recent work which interleaves retrieval with generation when producing an output, Iter-RetGen processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate Iter-RetGen on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation.', 'citationCount': 162, 'influentialCitationCount': 20, 'authors': [{'authorId': '144485528', 'name': 'Zhihong Shao'}, {'authorId': '2171182', 'name': 'Yeyun Gong'}, {'authorId': '1752875', 'name': 'Yelong Shen'}, {'authorId': '1730108', 'name': 'Minlie Huang'}, {'authorId': '46429989', 'name': 'Nan Duan'}, {'authorId': '2109136147', 'name': 'Weizhu Chen'}], 'publicationDate': '2023-05-24', 'year': 2023, 'isInfluential': False, 'intents': ['background'], 'contexts': ['…generation-augmented retrieval (GAR, Mao et al., 2020) that facilitates future generation cycles, while our parallel generation of community answers from these summaries is a kind of iterative (Iter-RetGen, Shao et al., 2023) or federated (FeB4RAG, Wang et al., 2024) retrieval-generation strategy.'], 'sim_socre': 0.7086438203258869}\n",
      "{'title': 'Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT', 'abstract': 'In this paper, we aim to develop a large language model (LLM) with the reasoning ability on complex graph data. Currently, LLMs have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with multi-modal data. However, when it comes to the graph learning tasks, existing LLMs present very serious flaws due to their several inherited weaknesses in performing {multi-step logic reasoning}, {precise mathematical calculation} and {perception about the spatial and temporal factors}. To address such challenges, in this paper, we will investigate the principles, methodologies and algorithms to empower existing LLMs with graph reasoning ability, which will have tremendous impacts on the current research of both LLMs and graph learning. Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with prompts augmented by ChatGPT to use external graph reasoning API tools. Specifically, we will investigate to teach Graph-ToolFormer to handle various graph data reasoning tasks in this paper, including both (1) very basic graph data loading and graph property reasoning tasks, ranging from simple graph order and size to the graph diameter and periphery, and (2) more advanced reasoning tasks on real-world graph data, such as bibliographic networks, protein molecules, sequential recommender systems, social networks and knowledge graphs.', 'citationCount': 69, 'influentialCitationCount': 6, 'authors': [{'authorId': '2144138716', 'name': 'Jiawei Zhang'}], 'publicationDate': '2023-04-10', 'year': 2023, 'isInfluential': False, 'intents': ['background'], 'contexts': ['…graph (KAPING, Baek et al., 2023), where subsets of the graph structure (G-Retriever, He et al., 2024) or derived graph metrics (Graph-ToolFormer, Zhang, 2023) are the objects of enquiry, where narrative outputs are strongly grounded in the facts of retrieved subgraphs (SURGE, Kang et al.,…'], 'sim_socre': 0.7109830124859354}\n",
      "{'title': 'Text Summarization with Latent Queries', 'abstract': 'The availability of large-scale datasets has driven the development of neural models that create summaries from single documents, for generic purposes. When using a summarization system, users often have specific intents with various language realizations, which, depending on the information need, can range from a single keyword to a long narrative composed of multiple questions. Existing summarization systems, however, often either fail to support or act robustly on this query focused summarization task. We introduce LaQSum, the first unified text summarization system that learns Latent Queries from documents for abstractive summarization with any existing query forms. Under a deep generative framework, our system jointly optimizes a latent query model and a conditional language model, allowing users to plug-and-play queries of any type at test time. Despite learning from only generic summarization data and requiring no further optimization for downstream summarization tasks, our system robustly outperforms strong comparison systems across summarization benchmarks with different query types, document settings, and target domains.', 'citationCount': 10, 'influentialCitationCount': 0, 'authors': [{'authorId': '115986373', 'name': 'Yumo Xu'}, {'authorId': '1747893', 'name': 'Mirella Lapata'}], 'publicationDate': '2021-05-31', 'year': 2021, 'isInfluential': False, 'intents': ['methodology'], 'contexts': ['Similarly, methods for extracting latent summarization queries from source texts also exist (Xu and Lapata, 2021), but such extracted questions can target details that betray prior knowledge of the texts.'], 'sim_socre': 0.721346644911684}\n",
      "{'title': 'Generation-Augmented Retrieval for Open-Domain Question Answering', 'abstract': 'We propose Generation-Augmented Retrieval (GAR) for answering open-domain questions, which augments a query through text generation of heuristically discovered relevant contexts without external resources as supervision. We demonstrate that the generated contexts substantially enrich the semantics of the queries and GAR with sparse representations (BM25) achieves comparable or better performance than state-of-the-art dense retrieval methods such as DPR. We show that generating diverse contexts for a query is beneficial as fusing their results consistently yields better retrieval accuracy. Moreover, as sparse and dense representations are often complementary, GAR can be easily combined with DPR to achieve even better performance. GAR achieves state-of-the-art performance on Natural Questions and TriviaQA datasets under the extractive QA setup when equipped with an extractive reader, and consistently outperforms other retrieval methods when the same generative reader is used.', 'citationCount': 212, 'influentialCitationCount': 27, 'authors': [{'authorId': '3375249', 'name': 'Yuning Mao'}, {'authorId': '2107782398', 'name': 'Pengcheng He'}, {'authorId': '2108860856', 'name': 'Xiaodong Liu'}, {'authorId': '1752875', 'name': 'Yelong Shen'}, {'authorId': '1800422', 'name': 'Jianfeng Gao'}, {'authorId': '153034701', 'name': 'Jiawei Han'}, {'authorId': '2109136147', 'name': 'Weizhu Chen'}], 'publicationDate': '2020-09-17', 'year': 2020, 'isInfluential': False, 'intents': ['background'], 'contexts': ['For example, our community summaries are a kind of self-memory (Selfmem, Cheng et al., 2024) for generation-augmented retrieval (GAR, Mao et al., 2020) that facilitates future generation cycles, while our parallel generation of community answers from these summaries is a kind of iterative…'], 'sim_socre': 0.7215240784553416}\n",
      "{'title': 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks', 'abstract': 'Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.', 'citationCount': 4547, 'influentialCitationCount': 492, 'authors': [{'authorId': '145222654', 'name': 'Patrick Lewis'}, {'authorId': '3439053', 'name': 'Ethan Perez'}, {'authorId': '1716179427', 'name': 'Aleksandara Piktus'}, {'authorId': '40052301', 'name': 'F. Petroni'}, {'authorId': '2067091563', 'name': 'Vladimir Karpukhin'}, {'authorId': '39589154', 'name': 'Naman Goyal'}, {'authorId': '103131985', 'name': 'Heinrich Kuttler'}, {'authorId': '35084211', 'name': 'M. Lewis'}, {'authorId': '144105277', 'name': 'Wen-tau Yih'}, {'authorId': '2620211', 'name': 'Tim Rocktäschel'}, {'authorId': '48662861', 'name': 'Sebastian Riedel'}, {'authorId': '1743722', 'name': 'Douwe Kiela'}], 'publicationDate': '2020-05-22', 'year': 2020, 'isInfluential': False, 'intents': ['background'], 'contexts': ['Retrieval-augmented generation (RAG, Lewis et al., 2020) is an established approach to answering user questions over entire datasets, but it is designed for situations where these answers are contained locally within regions of text whose retrieval provides sufficient grounding for the generation…'], 'sim_socre': 0.7513609187920622}\n",
      "{'title': 'Fast unfolding of communities in large networks', 'abstract': 'We propose a simple method to extract the community structure of large networks. Our method is a heuristic method that is based on modularity optimization. It is shown to outperform all other known community detection methods in terms of computation time. Moreover, the quality of the communities detected is very good, as measured by the so-called modularity. This is shown first by identifying language communities in a Belgian mobile phone network of 2 million customers and by analysing a web graph of 118 million nodes and more than one billion links. The accuracy of our algorithm is also verified on ad hoc modular networks.', 'citationCount': 17304, 'influentialCitationCount': 1537, 'authors': [{'authorId': '1715830', 'name': 'V. Blondel'}, {'authorId': '2562434', 'name': 'Jean-Loup Guillaume'}, {'authorId': '1706831', 'name': 'R. Lambiotte'}, {'authorId': '7499393', 'name': 'E. Lefebvre'}], 'publicationDate': '2008-03-04', 'year': 2008, 'isInfluential': True, 'intents': ['background'], 'contexts': ['…we focus on a previously unexplored quality of graphs in this context: their inherent modularity (Newman, 2006) and the ability of community detection algorithms to partition graphs into modular communities of closely-related nodes (e.g., Louvain, Blondel et al., 2008; Leiden, Traag et al., 2019).', 'In contrast with related work that exploits the structured retrieval and traversal affordances of graph indexes (subsection 4.2), we focus on a previously unexplored quality of graphs in this context: their inherent modularity (Newman, 2006) and the ability of community detection algorithms to partition graphs into modular communities of closely-related nodes (e.g., Louvain, Blondel et al., 2008; Leiden, Traag et al., 2019).'], 'sim_socre': 0.5099147767899468}\n",
      "{'title': 'Modularity and community structure in networks.', 'abstract': 'Many networks of interest in the sciences, including social networks, computer networks, and metabolic and regulatory networks, are found to divide naturally into communities or modules. The problem of detecting and characterizing this community structure is one of the outstanding issues in the study of networked systems. One highly effective approach is the optimization of the quality function known as \"modularity\" over the possible divisions of a network. Here I show that the modularity can be expressed in terms of the eigenvectors of a characteristic matrix for the network, which I call the modularity matrix, and that this expression leads to a spectral algorithm for community detection that returns results of demonstrably higher quality than competing methods in shorter running times. I illustrate the method with applications to several published network data sets.', 'citationCount': 11157, 'influentialCitationCount': 919, 'authors': [{'authorId': '152618356', 'name': 'M. Newman'}], 'publicationDate': '2006-02-17', 'year': 2006, 'isInfluential': True, 'intents': ['background'], 'contexts': ['…affordances of graph indexes (subsection 4.2), we focus on a previously unexplored quality of graphs in this context: their inherent modularity (Newman, 2006) and the ability of community detection algorithms to partition graphs into modular communities of closely-related nodes (e.g., Louvain,…'], 'sim_socre': 0.5153210880170565}\n"
     ]
    }
   ],
   "source": [
    "paper_authors_ids = [x.get('authorId') for x in paper_metadata.get('authors', [])]\n",
    "for item in citing_metadata_lst:\n",
    "    citing_authors_ids = [x.get('authorId') for x in item.get('authors', [])]\n",
    "    if (item.get('sim_socre', 0) > 0.7 \n",
    "        or (item.get('isInfluential', False) == True and item.get('sim_socre', 0) > 0.5)\n",
    "        or (len(item.get('contexts', [])) > 3 and item.get('sim_socre', 0) > 0.5)\n",
    "        or (len(set(paper_authors_ids) & set(citing_authors_ids)) > 0 and item.get('sim_socre', 0) > 0.5)):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citedby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get citedby paper metadata\n",
    "citedby_info_keys = ['isInfluential', 'intents', 'contexts']\n",
    "paper_metadata_keys = ['title', 'abstract', 'citationCount', 'influentialCitationCount', 'authors', 'publicationDate', 'year']\n",
    "\n",
    "citedby_metadata_lst = []\n",
    "for item in paper_citedby_info:\n",
    "    cited_info = filter_and_reorder_dict(item, citedby_info_keys)\n",
    "\n",
    "    cited_paper_info = item.get('citingPaper', {})\n",
    "    if cited_paper_info and cited_paper_info != {}:\n",
    "        cited_paper_metadata = filter_and_reorder_dict(cited_paper_info, paper_metadata_keys)\n",
    "        cited_metadata = {**cited_paper_metadata, **cited_info}\n",
    "        citedby_metadata_lst.append(cited_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get citing paper abstracts\n",
    "abstracts = []\n",
    "for item in citedby_metadata_lst:\n",
    "    abstracts.append(item.get('abstract') if item.get('abstract') else 'NAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate abstract similarity\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY_1')\n",
    "gemini_model_name = \"models/text-embedding-004\"\n",
    "texts = [paper_metadata['abstract']] + abstracts\n",
    "n_concurrent = 5\n",
    "embeds = await gemini_embedding_async(gemini_api_key, gemini_model_name, texts, n_concurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "similarity_matrix = semantic_similarity_matrix(embeds[0], embeds[1:])\n",
    "similarity_matrix = np.array(similarity_matrix)\n",
    "\n",
    "abstracts_similarity_scores = similarity_matrix[0].tolist()\n",
    "\n",
    "assert len(citedby_metadata_lst) == len(abstracts_similarity_scores)\n",
    "for idx, item in enumerate(citedby_metadata_lst):\n",
    "    item['sim_socre'] = abstracts_similarity_scores[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'PASemiQA: Plan-Assisted Agent for Question Answering on Semi-Structured Data with Text and Relational Information', 'abstract': 'Large language models (LLMs) have shown impressive abilities in answering questions across various domains, but they often encounter hallucination issues on questions that require professional and up-to-date knowledge. To address this limitation, retrieval-augmented generation (RAG) techniques have been proposed, which retrieve relevant information from external sources to inform their responses. However, existing RAG methods typically focus on a single type of external data, such as vectorized text database or knowledge graphs, and cannot well handle real-world questions on semi-structured data containing both text and relational information. To bridge this gap, we introduce PASemiQA, a novel approach that jointly leverages text and relational information in semi-structured data to answer questions. PASemiQA first generates a plan to identify relevant text and relational information to answer the question in semi-structured data, and then uses an LLM agent to traverse the semi-structured data and extract necessary information. Our empirical results demonstrate the effectiveness of PASemiQA across different semi-structured datasets from various domains, showcasing its potential to improve the accuracy and reliability of question answering systems on semi-structured data.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': None, 'name': 'Hansi Yang'}, {'authorId': None, 'name': 'Qi Zhang'}, {'authorId': None, 'name': 'Wei Jiang'}, {'authorId': None, 'name': 'Jianguo Li'}], 'publicationDate': '2025-02-28', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': ['GraphRAG [7] proposes a RAG pipeline on a set of text chunks that are connected based on their semantic similarities.'], 'sim_socre': 0.7759063048853481}\n",
      "{'title': 'A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation', 'abstract': 'The integration of Knowledge Graphs (KGs) into the Retrieval Augmented Generation (RAG) framework has attracted significant interest, with early studies showing promise in mitigating hallucinations and improving model accuracy. However, a systematic understanding and comparative analysis of the rapidly emerging KG-RAG methods are still lacking. This paper seeks to lay the foundation for systematically answering the question of when and how to use KG-RAG by analyzing their performance in various application scenarios associated with different technical configurations. After outlining the mind map using KG-RAG framework and summarizing its popular pipeline, we conduct a pilot empirical study of KG-RAG works to reimplement and evaluate 6 KG-RAG methods across 7 datasets in diverse scenarios, analyzing the impact of 9 KG-RAG configurations in combination with 17 LLMs. Our results underscore the critical role of appropriate application conditions and optimal configurations of KG-RAG components.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': None, 'name': 'Xujie Yuan'}, {'authorId': None, 'name': 'Yongxu Liu'}, {'authorId': '51129379', 'name': 'Shimin Di'}, {'authorId': None, 'name': 'Shiwen Wu'}, {'authorId': None, 'name': 'Libin Zheng'}, {'authorId': '2312769092', 'name': 'Rui Meng'}, {'authorId': '2155797559', 'name': 'Xiaofang Zhou'}, {'authorId': None, 'name': 'Lei Chen'}, {'authorId': None, 'name': 'Jian Yin'}], 'publicationDate': '2025-02-28', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': ['To address above limitations, graph-based RAG (Edge et al., 2024), particularly those incorporating Knowledge Graphs (KGs) known as KG-RAG, has emerged as a promising paradigm (Zhang et al., 2022; Guan et al., 2024; Kim et al., 2023; Saleh et al., 2024).'], 'sim_socre': 0.7278247224110785}\n",
      "{'title': 'KiRAG: Knowledge-Driven Iterative Retriever for Enhancing Retrieval-Augmented Generation', 'abstract': 'Iterative retrieval-augmented generation (iRAG) models offer an effective approach for multi-hop question answering (QA). However, their retrieval process faces two key challenges: (1) it can be disrupted by irrelevant documents or factually inaccurate chain-of-thoughts; (2) their retrievers are not designed to dynamically adapt to the evolving information needs in multi-step reasoning, making it difficult to identify and retrieve the missing information required at each iterative step. Therefore, we propose KiRAG, which uses a knowledge-driven iterative retriever model to enhance the retrieval process of iRAG. Specifically, KiRAG decomposes documents into knowledge triples and performs iterative retrieval with these triples to enable a factually reliable retrieval process. Moreover, KiRAG integrates reasoning into the retrieval process to dynamically identify and retrieve knowledge that bridges information gaps, effectively adapting to the evolving information needs. Empirical results show that KiRAG significantly outperforms existing iRAG models, with an average improvement of 9.40% in R@3 and 5.14% in F1 on multi-hop QA.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '1384241384', 'name': 'Jinyuan Fang'}, {'authorId': '2290004156', 'name': 'Zaiqiao Meng'}, {'authorId': '2260652308', 'name': 'Craig Macdonald'}], 'publicationDate': '2025-02-25', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['Building on recent advancements in extracting knowledge triples using LLMs (Edge et al., 2024; Fang et al., 2024b), we employ in-context learning to prompt an LLM to extract knowledge triples for each retrieved document independently.', 'For the Reasoning Chain Constructor , we try different LLMs, including Llama3, Mistral (Jiang et al., 2023a) and Gemma2 (Team et al., 2024), to select a triple to extend the partial reasoning chain for subsequent retrieval.', '…2014) for additional context (Yu et al., 2022; Sun et al., 2024), while others generate KGs from documents to improve knowledge organisation (Edge et al., 2024; Gutiérrez et al., 2024; Chen et al., 2024) or enhance reader comprehension (Li and Du, 2023; Fang et al., 2024a,b; Panda et al.,…', 'While further training the Constructor could potential improve performance, we choose to keep it frozen to maintain our framework’ adaptability to different LLMs, rather than relying on a specific fine-tuned LLM. Appendix C.9 provides a detailed analysis of the performance using different LLM-based Constructor within our framework.', 'This improvement stems from LLM’s tendency to generate hallucinated CoT.', 'For instance, IRCoT (Trivedi et al., 2023) use LLM-generated chain-of-thoughts for retrieval, while DRAGIN (Su et al., 2024) dynamically decides when and what to retrieve based on the LLM’s information needs.'], 'sim_socre': 0.6969400576813594}\n",
      "{'title': 'GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking', 'abstract': 'Large language models (LLMs) are widely used, but they often generate subtle factual errors, especially in long-form text. These errors are fatal in some specialized domains such as medicine. Existing fact-checking with grounding documents methods face two main challenges: (1) they struggle to understand complex multihop relations in long documents, often overlooking subtle factual errors; (2) most specialized methods rely on pairwise comparisons, requiring multiple model calls, leading to high resource and computational costs. To address these challenges, we propose \\\\textbf{\\\\textit{GraphCheck}}, a fact-checking framework that uses extracted knowledge graphs to enhance text representation. Graph Neural Networks further process these graphs as a soft prompt, enabling LLMs to incorporate structured knowledge more effectively. Enhanced with graph-based reasoning, GraphCheck captures multihop reasoning chains which are often overlooked by existing methods, enabling precise and efficient fact-checking in a single inference call. Experimental results on seven benchmarks spanning both general and medical domains demonstrate a 6.1\\\\% overall improvement over baseline models. Notably, GraphCheck outperforms existing specialized fact-checkers and achieves comparable performance with state-of-the-art LLMs, such as DeepSeek-V3 and OpenAI-o1, with significantly fewer parameters.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2347033747', 'name': 'Yingjian Chen'}, {'authorId': '2336717485', 'name': 'Haoran Liu'}, {'authorId': '2346992198', 'name': 'Yinhong Liu'}, {'authorId': '2347582099', 'name': 'Rui Yang'}, {'authorId': None, 'name': 'Han Yuan'}, {'authorId': '2326109980', 'name': 'Yanran Fu'}, {'authorId': None, 'name': 'Pengyuan Zhou'}, {'authorId': '2347043169', 'name': 'Qingyu Chen'}, {'authorId': '2312210196', 'name': 'James Caverlee'}, {'authorId': '2248289605', 'name': 'Irene Li'}], 'publicationDate': '2025-02-23', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['Implementation Details of GraphRAG.', 'The results show that GraphRAG underperforms our proposed GraphCheck, which is based on Llama3.', 'Given that GraphRAG is a general-purpose framework rather than one specifically designed for fact-checking, we suggest it may not be an ideal approach for this task.', 'In the Query phase, GraphRAG retrieves the relevant triples from the knowledge base and invokes GPT-4o for inference to determine whether the claim is supported or not.', 'We compare GraphRAG and GraphCheck in Table 6.', 'Although GraphRAG is not typically used for fact-checking, its popularity motivated us to adapt it for this purpose.', 'Additionally, we also consider graph-based methods, namely GraphEval (Sansford et al., 2024) and GraphRAG (Edge et al., 2024).', 'To streamline our implementation process, we leveraged the approach from the open-source nano-GraphRAG project 9 for our testing phase.'], 'sim_socre': 0.6969592605776697}\n",
      "{'title': 'From Documents to Dialogue: Building KG-RAG Enhanced AI Assistants', 'abstract': 'The Adobe Experience Platform AI Assistant is a conversational tool that enables organizations to interact seamlessly with proprietary enterprise data through a chatbot. However, due to access restrictions, Large Language Models (LLMs) cannot retrieve these internal documents, limiting their ability to generate accurate zero-shot responses. To overcome this limitation, we use a Retrieval-Augmented Generation (RAG) framework powered by a Knowledge Graph (KG) to retrieve relevant information from external knowledge sources, enabling LLMs to answer questions over private or previously unseen document collections. In this paper, we propose a novel approach for building a high-quality, low-noise KG. We apply several techniques, including incremental entity resolution using seed concepts, similarity-based filtering to deduplicate entries, assigning confidence scores to entity-relation pairs to filter for high-confidence pairs, and linking facts to source documents for provenance. Our KG-RAG system retrieves relevant tuples, which are added to the user prompts context before being sent to the LLM generating the response. Our evaluation demonstrates that this approach significantly enhances response relevance, reducing irrelevant answers by over 50% and increasing fully relevant answers by 88% compared to the existing production system.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2346835775', 'name': 'Manisha Mukherjee'}, {'authorId': '2261424174', 'name': 'Sungchul Kim'}, {'authorId': '2346933519', 'name': 'Xiang Chen'}, {'authorId': '2346911652', 'name': 'Dan Luo'}, {'authorId': '2344595347', 'name': 'Tong Yu'}, {'authorId': '2280540984', 'name': 'Tung Mai'}], 'publicationDate': '2025-02-21', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': ['Edge et al.[7] introduced a graph-enhanced retrieval mechanism, demonstrating that structured data linked through relationships can significantly improve contextual relevance in query responses.', 'Recent approaches also incorporate structured Knowledge Graphs (KGs) to improve semantic retrieval [7].', 'In contrast, [3] includes provenance but does not incorporate the other features, while [7] assigns confidence scores but also performs community detection on the graph and generates summaries for each community using LLMs.'], 'sim_socre': 0.7600261637554051}\n",
      "{'title': 'Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering', 'abstract': 'In this paper, we identify a critical problem,\"lost-in-retrieval\", in retrieval-augmented multi-hop question answering (QA): the key entities are missed in LLMs\\' sub-question decomposition.\"Lost-in-retrieval\"significantly degrades the retrieval performance, which disrupts the reasoning chain and leads to the incorrect answers. To resolve this problem, we propose a progressive retrieval and rewriting method, namely ChainRAG, which sequentially handles each sub-question by completing missing key entities and retrieving relevant sentences from a sentence graph for answer generation. Each step in our retrieval and rewriting process builds upon the previous one, creating a seamless chain that leads to accurate retrieval and answers. Finally, all retrieved sentences and sub-question answers are integrated to generate a comprehensive answer to the original question. We evaluate ChainRAG on three multi-hop QA datasets$\\\\unicode{x2013}$MuSiQue, 2Wiki, and HotpotQA$\\\\unicode{x2013}$using three large language models: GPT4o-mini, Qwen2.5-72B, and GLM-4-Plus. Empirical results demonstrate that ChainRAG consistently outperforms baselines in both effectiveness and efficiency.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2346786417', 'name': 'Rongzhi Zhu'}, {'authorId': '2304301341', 'name': 'Xiangyu Liu'}, {'authorId': '2109745316', 'name': 'Zequn Sun'}, {'authorId': '2346427018', 'name': 'Yiwei Wang'}, {'authorId': '2273310686', 'name': 'Wei Hu'}], 'publicationDate': '2025-02-20', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': ['GraphRAG (Edge et al., 2024), GraphReader (Li et al., 2024b), and Hip-poRAG (Gutiérrez et al., 2024) use LLMs to extract entities and relations from the text, constructing knowledge graphs (KGs).'], 'sim_socre': 0.7472097924816492}\n",
      "{'title': 'Is Relevance Propagated from Retriever to Generator in RAG?', 'abstract': \"Retrieval Augmented Generation (RAG) is a framework for incorporating external knowledge, usually in the form of a set of documents retrieved from a collection, as a part of a prompt to a large language model (LLM) to potentially improve the performance of a downstream task, such as question answering. Different from a standard retrieval task's objective of maximising the relevance of a set of top-ranked documents, a RAG system's objective is rather to maximise their total utility, where the utility of a document indicates whether including it as a part of the additional contextual information in an LLM prompt improves a downstream task. Existing studies investigate the role of the relevance of a RAG context for knowledge-intensive language tasks (KILT), where relevance essentially takes the form of answer containment. In contrast, in our work, relevance corresponds to that of topical overlap between a query and a document for an information seeking task. Specifically, we make use of an IR test collection to empirically investigate whether a RAG context comprised of topically relevant documents leads to improved downstream performance. Our experiments lead to the following findings: (a) there is a small positive correlation between relevance and utility; (b) this correlation decreases with increasing context sizes (higher values of k in k-shot); and (c) a more effective retrieval model generally leads to better downstream RAG performance.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2346853822', 'name': 'Fangzheng Tian'}, {'authorId': '2280136919', 'name': 'Debasis Ganguly'}, {'authorId': '2346834907', 'name': 'Craig Macdonald'}], 'publicationDate': '2025-02-20', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': ['…studies have adapted it for a number of different applications, e.g., for improving the performance of knowledge-intensive language tasks (KILT) [37] which include question answering [21,44], hallucination and factual incorrectness mitigation [19], summarisation [13], software code generation [25].'], 'sim_socre': 0.7595561488033015}\n",
      "{'title': 'Explore-Construct-Filter: An Automated Framework for Rich and Reliable API Knowledge Graph Construction', 'abstract': \"The API Knowledge Graph (API KG) is a structured network that models API entities and their relations, providing essential semantic insights for tasks such as API recommendation, code generation, and API misuse detection. However, constructing a knowledge-rich and reliable API KG presents several challenges. Existing schema-based methods rely heavily on manual annotations to design KG schemas, leading to excessive manual overhead. On the other hand, schema-free methods, due to the lack of schema guidance, are prone to introducing noise, reducing the KG's reliability. To address these issues, we propose the Explore-Construct-Filter framework, an automated approach for API KG construction based on large language models (LLMs). This framework consists of three key modules: 1) KG exploration: LLMs simulate the workflow of annotators to automatically design a schema with comprehensive type triples, minimizing human intervention; 2) KG construction: Guided by the schema, LLMs extract instance triples to construct a rich yet unreliable API KG; 3) KG filtering: Removing invalid type triples and suspicious instance triples to construct a rich and reliable API KG. Experimental results demonstrate that our method surpasses the state-of-the-art method, achieving a 25.2% improvement in F1 score. Moreover, the Explore-Construct-Filter framework proves effective, with the KG exploration module increasing KG richness by 133.6% and the KG filtering module improving reliability by 26.6%. Finally, cross-model experiments confirm the generalizability of our framework.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2199853522', 'name': 'Yanbang Sun'}, {'authorId': '2338409600', 'name': 'Qing Huang'}, {'authorId': None, 'name': 'Xiaoxue Ren'}, {'authorId': '2346110444', 'name': 'Zhenchang Xing'}, {'authorId': '2346275218', 'name': 'Xiaohong Li'}, {'authorId': '2346270779', 'name': 'Junjie Wang'}], 'publicationDate': '2025-02-19', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['For GraphRAG [14], the lack of KG schema guidance during the extraction process leads to noise in the results.', 'In the field of natural language processing, schema-free methods [14]–[17] are another mainstream approach for constructing KGs. Unlike schema-based methods, schema-free methods extract instance triples directly from text, thereby reducing labor costs.', 'GraphRAG [14] and EDC [15] are schema-free methods, with the former lacking relations types (e.g., the type triple (class, null, class)) and the latter lacking entity types (e.g., the type triple (null, check, null)).', 'One representative schema-free method is GraphRAG [14].', 'We obtained its code from Github [36] and tested its performance using the same testing method as MKC. • GraphRAG [14] is used to improve the efficiency of retrieving information from the KG.', 'Integrating our method with existing KG retrieval technologies, such as GraphRAG [14], can form a comprehensive tool for knowledge extraction, analysis, and utilization.'], 'sim_socre': 0.6235051934481903}\n",
      "{'title': 'PathRAG: Pruning Graph-based Retrieval Augmented Generation with Relational Paths', 'abstract': 'Retrieval-augmented generation (RAG) improves the response quality of large language models (LLMs) by retrieving knowledge from external databases. Typical RAG approaches split the text database into chunks, organizing them in a flat structure for efficient searches. To better capture the inherent dependencies and structured relationships across the text database, researchers propose to organize textual information into an indexing graph, known asgraph-based RAG. However, we argue that the limitation of current graph-based RAG methods lies in the redundancy of the retrieved information, rather than its insufficiency. Moreover, previous methods use a flat structure to organize retrieved information within the prompts, leading to suboptimal performance. To overcome these limitations, we propose PathRAG, which retrieves key relational paths from the indexing graph, and converts these paths into textual form for prompting LLMs. Specifically, PathRAG effectively reduces redundant information with flow-based pruning, while guiding LLMs to generate more logical and coherent responses with path-based prompting. Experimental results show that PathRAG consistently outperforms state-of-the-art baselines across six datasets and five evaluation dimensions. The code is available at the following link: https://github.com/BUPT-GAMMA/PathRAG', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2257046991', 'name': 'Boyu Chen'}, {'authorId': '2346899917', 'name': 'Zirui Guo'}, {'authorId': '2347018072', 'name': 'Zidan Yang'}, {'authorId': '2346897152', 'name': 'Yuluo Chen'}, {'authorId': '2260645232', 'name': 'Junze Chen'}, {'authorId': '2346930979', 'name': 'Zhenghao Liu'}, {'authorId': '2347002484', 'name': 'Chuan Shi'}, {'authorId': '2346977661', 'name': 'Cheng Yang'}], 'publicationDate': '2025-02-18', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['(Edge et al., 2024) uses all the information within certain communities, while Ligh-tRAG (Guo et al., 2024) uses all the immediate neighbors of query-related nodes.', 'To better capture the inherent dependencies and structured relationships across texts in a database, researchers have introduced graph-based RAG (Edge et al., 2024; Guo et al., 2024), which organizes textual information into an indexing graph.', 'GraphRAG (Edge et al., 2024) first applies community detection algorithms on the graph, and then gradually aggregates the information from sub-communities to form higher-level community information.', 'Instead of utilizing pre-constructed KGs, graph-based RAG (Edge et al., 2024; Guo et al., 2024) typically organizes text databases as text-associated graphs, and focuses on global-level questions that need the information from multiple segments across a database.', 'Also, the indexing graphs for different graph-based RAG methods are the same as GraphRAG (Edge et al., 2024).', 'We compare PathRAG with four state-of-the-art methods: NaiveRAG (Gao et al., 2023), HyDE (Gao et al., 2022b), GraphRAG (Edge et al., 2024), and LightRAG (Guo et al., 2024).', 'However, most text-based RAG methods use a flat organization of text segments, and fail to capture essential relationships between chunks ( e.g., the contextual dependencies), limiting the quality of LLM-generated responses (Edge et al., 2024; Guo et al., 2024).', 'For example, GraphRAG (Edge et al., 2024) first applies community detection on the graph, and then gradually summarizes the information in each community.'], 'sim_socre': 0.799424845031457}\n",
      "{'title': 'HopRAG: Multi-Hop Reasoning for Logic-Aware Retrieval-Augmented Generation', 'abstract': \"Retrieval-Augmented Generation (RAG) systems often struggle with imperfect retrieval, as traditional retrievers focus on lexical or semantic similarity rather than logical relevance. To address this, we propose HopRAG, a novel RAG framework that augments retrieval with logical reasoning through graph-structured knowledge exploration. During indexing, HopRAG constructs a passage graph, with text chunks as vertices and logical connections established via LLM-generated pseudo-queries as edges. During retrieval, it employs a retrieve-reason-prune mechanism: starting with lexically or semantically similar passages, the system explores multi-hop neighbors guided by pseudo-queries and LLM reasoning to identify truly relevant ones. Extensive experiments demonstrate HopRAG's superiority, achieving 76.78\\\\% higher answer accuracy and 65.07\\\\% improved retrieval F1 score compared to conventional methods. The repository is available at https://github.com/LIU-Hao-2002/HopRAG.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2345972557', 'name': 'Hao Liu'}, {'authorId': '2288675277', 'name': 'Zhengren Wang'}, {'authorId': '2346461266', 'name': 'Xi Chen'}, {'authorId': '2268429641', 'name': 'Zhiyu Li'}, {'authorId': '2268399953', 'name': 'Feiyu Xiong'}, {'authorId': None, 'name': 'Qinhan Yu'}, {'authorId': '2344098350', 'name': 'Wentao Zhang'}], 'publicationDate': '2025-02-18', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': [], 'sim_socre': 0.731055733306305}\n",
      "{'title': 'A Research of Challenges and Solutions in Retrieval Augmented Generation (RAG) Systems', 'abstract': \"Retrieval-Augmented Generation (RAG) systems represent a significant innovation in the field of Natural Language Processing (NLP), ingeniously integrating Large Language Models (LLMs) with dynamic external knowledge retrieval. This amalgamation not only enhances the models' responsiveness to real-world knowledge but also addresses the limitations of conventional generative models in terms of knowledge update velocity and factual accuracy. This review examines the challenges faced by RAG systems and their solutions. It delves into the central architecture of RAG systems, encompassing retrieval components, generative components, and knowledge bases, with a particular focus on recent advancements that have expanded the boundaries of performance and functionality. The study critically analyzes major challenges such as retrieval efficiency and dynamic knowledge management. This paper evaluates various advanced solutions proposed in recent literature, comparing their efficacy and discussing the trade-offs involved. Ultimately, this paper aims to provide researchers, developers, and users of RAG systems with a comprehensive perspective, fostering ongoing innovation and the expansion of applications in this domain.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2347843333', 'name': 'Jiafeng Gu'}], 'publicationDate': '2025-02-18', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': [\"GraphRAG's use of graph machine learning algorithms for semantic aggregation and hierarchical analysis enables it to answer high-level abstract or summary questions, showcasing the potential of structured knowledge in RAG systems [16].\"], 'sim_socre': 0.7344702184075671}\n",
      "{'title': 'RAG vs. GraphRAG: A Systematic Evaluation and Key Insights', 'abstract': 'Retrieval-Augmented Generation (RAG) enhances the performance of LLMs across various tasks by retrieving relevant information from external sources, particularly on text-based data. For structured data, such as knowledge graphs, GraphRAG has been widely used to retrieve relevant information. However, recent studies have revealed that structuring implicit knowledge from text into graphs can benefit certain tasks, extending the application of GraphRAG from graph data to general text-based data. Despite their successful extensions, most applications of GraphRAG for text data have been designed for specific tasks and datasets, lacking a systematic evaluation and comparison between RAG and GraphRAG on widely used text-based benchmarks. In this paper, we systematically evaluate RAG and GraphRAG on well-established benchmark tasks, such as Question Answering and Query-based Summarization. Our results highlight the distinct strengths of RAG and GraphRAG across different tasks and evaluation perspectives. Inspired by these observations, we investigate strategies to integrate their strengths to improve downstream tasks. Additionally, we provide an in-depth discussion of the shortcomings of current GraphRAG approaches and outline directions for future research.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2049039664', 'name': 'Haoyu Han'}, {'authorId': '2220302956', 'name': 'Harry Shomer'}, {'authorId': '2346107355', 'name': 'Yu Wang'}, {'authorId': '2338562947', 'name': 'Yongjia Lei'}, {'authorId': '2338271219', 'name': 'Kai Guo'}, {'authorId': '2293482433', 'name': 'Zhigang Hua'}, {'authorId': '2338267824', 'name': 'Bo Long'}, {'authorId': '2345866507', 'name': 'Hui Liu'}, {'authorId': '2330147642', 'name': 'Jiliang Tang'}], 'publicationDate': '2025-02-17', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['Edge et al. (2024) construct graphs from documents using LLMs, where nodes represent entities and edges capture relationships between them.', 'The Community-GraphRAG methods are implemented using Microsoft GraphRAG (Edge et al., 2024) 2 .', 'GraphRAG has also demonstrated its effectiveness in summarization tasks (Edge et al., 2024).', '…has also demonstrated its effectiveness for text-based tasks after structuring implicit knowledge from text into graph representations, benefiting applications such as global summarization (Edge et al., 2024; Zhang et al., 2024), planning (Lin et al., 2024) and reasoning (Han et al., 2025).', 'For the Community-based GraphRAG (Edge et al., 2024), in addition to generating KGs using LLMs, hierarchical communities are constructed using graph community detection algorithms, as shown in Figure 1.', 'However, Edge et al. (2024) only evaluate its effectiveness on the global summarization task and rely on LLM-as-a-Judge (Zheng et al., 2023b) for performance assessment.', '…GraphRAG (Liu, 2022), which ex-1 tracts a Knowledge Graph (KG) from text and performs retrieval solely based on the KG and (2) Community-based GraphRAG (Edge et al., 2024), which retrieves information not only from the constructed KG but also from hierarchical communities within the graph.', 'There are two key differences between our evaluation and Edge et al. (2024).', 'Second, Edge et al. (2024) assess performance by comparing RAG and GraphRAG outputs using LLM-as-a-Judge without ground truth, whereas we evaluate results against ground truth summaries using ROUGE and BERTScore.', 'This contrasts with the findings of Edge et al. (2024), where Community-based GraphRAG with global search outperformed both local search and RAG.'], 'sim_socre': 0.8731067952112295}\n",
      "{'title': 'A-MEM: Agentic Memory for LLM Agents', 'abstract': \"While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code is available at https://github.com/WujiangXu/AgenticMemory.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2305567453', 'name': 'Wujiang Xu'}, {'authorId': '2346815593', 'name': 'Zujie Liang'}, {'authorId': '2261740874', 'name': 'Kai Mei'}, {'authorId': '2296705466', 'name': 'Hang Gao'}, {'authorId': None, 'name': 'Juntao Tan'}, {'authorId': '2296729361', 'name': 'Yongfeng Zhang'}], 'publicationDate': '2025-02-17', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['Meanwhile, to improve structured memory organization, Mem0 (Dev and Taranjeet, 2024), following the principles of RAG (Edge et al., 2024; Lewis et al., 2020; Shi et al., 2024), incorporates graph databases for storage and retrieval processes.', 'Advanced RAG systems (Lin et al., 2023; Ilin, 2023) have evolved to include sophisticated pre-retrieval and post-retrieval optimizations.', 'Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to enhance LLMs by incorporating external knowledge sources (Lewis et al., 2020; Borgeaud et al., 2022; Gao et al., 2023).', 'The standard RAG (Yu et al., 2023a; Wang et al., 2023c) process involves indexing documents into chunks, retrieving relevant chunks based on semantic similarity, and augmenting the LLM’s prompt with this retrieved context for generation.', 'Building upon these foundations, recent researches has introduced agentic RAG systems that demonstrate more autonomous and adaptive behaviors in the retrieval process.', 'However, while agentic RAG approaches demonstrate agency in the retrieval phase by autonomously deciding when and what to retrieve (Asai et al., 2023; Jiang et al., 2023; Yu et al., 2023b), our agentic memory system exhibits agency at a more fundamental level through the autonomous evolution of its memory structure.', 'This fundamental distinction in agency between retrieval versus storage and evolution distinguishes our approach from agentic RAG systems, which maintain static knowledge bases despite their sophisticated retrieval mechanisms.'], 'sim_socre': 0.5961736829983608}\n",
      "{'title': 'NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM', 'abstract': \"Vision-and-Language Navigation (VLN) is an essential skill for embodied agents, allowing them to navigate in 3D environments following natural language instructions. High-performance navigation models require a large amount of training data, the high cost of manually annotating data has seriously hindered this field. Therefore, some previous methods translate trajectory videos into step-by-step instructions for expanding data, but such instructions do not match well with users' communication styles that briefly describe destinations or state specific needs. Moreover, local navigation trajectories overlook global context and high-level task planning. To address these issues, we propose NavRAG, a retrieval-augmented generation (RAG) framework that generates user demand instructions for VLN. NavRAG leverages LLM to build a hierarchical scene description tree for 3D scene understanding from global layout to local details, then simulates various user roles with specific demands to retrieve from the scene tree, generating diverse instructions with LLM. We annotate over 2 million navigation instructions across 861 scenes and evaluate the data quality and navigation performance of trained models.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2332527018', 'name': 'Zihan Wang'}, {'authorId': '2345871965', 'name': 'Yaohui Zhu'}, {'authorId': '2332479307', 'name': 'Gim Hee Lee'}, {'authorId': '2345843841', 'name': 'Yachun Fan'}], 'publicationDate': '2025-02-16', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['To validate the superiority of our scene description tree-based retrieval over traditional RAG methods ( e.g. , GraphRAG (Edge et al., 2024)), we also annotate 100 scenes through GraphRAG to evaluate instruction quality.', 'Over time, several innovations have expanded on this idea, including techniques like iterative knowledge retrieval (Shao et al., 2023), and the incorporation of knowledge graphs (Edge et al., 2024).', 'Comparing the first and last rows of Table 4 shows that the model trained with GraphRAG-annotated data performs poorly on its validation set, indicating low annotation quality.', 'Specifically, GraphRAG replaces the scene description tree with a knowledge graph built from view-level descriptions.', 'The last row of Table 3 Retrieval-Augmented Generation: NavRAG vs. GraphRAG.'], 'sim_socre': 0.6659031148543366}\n",
      "{'title': 'RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation', 'abstract': 'Retrieval-augmented language models often struggle with knowledge-intensive tasks due to inefficient retrieval, unstructured knowledge integration, and single-pass architectures. We present Retrieval-And-Structuring (RAS), a novel framework that dynamically constructs and reasons over query-specific knowledge graphs through iterative retrieval and structuring. RAS introduces four key technical innovations: (1) a themescoped retrieval mechanism that efficiently narrows the search space while maintaining retrieval quality, (2) an action planning module that determines knowledge needs and generates focused sub-queries, (3) a dynamic knowledge structuring approach that converts retrieved text into an evolving knowledge graph, and (4) a graph-augmented answering component that leverages the accumulated structured information. Our framework achieves state-of-the-art performance, surpassing leading baselines by 6.4% with open-source language models and 7.0% with proprietary models on seven knowledge-intensive generation datasets across all evaluation metrics. Detailed ablation studies verify the contribution of each technical component to the overall system performance.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2149498192', 'name': 'Pengcheng Jiang'}, {'authorId': '2283520647', 'name': 'Lang Cao'}, {'authorId': '2346786391', 'name': 'Ruike Zhu'}, {'authorId': None, 'name': 'Minhao Jiang'}, {'authorId': '48379289', 'name': 'Yunyi Zhang'}, {'authorId': '2249887353', 'name': 'Jimeng Sun'}, {'authorId': '2284641156', 'name': 'Jiawei Han'}], 'publicationDate': '2025-02-16', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['Based on the findings, G-Retriever (He et al., 2024) constructs subgraphs by retrieving relevant entities and relations from a global KG, using these as structured knowledge input for LLMs. GraphRAG (Edge et al., 2024) employs an alternative strategy, extracting a comprehensive global KG from the corpus, identifying meaningful clusters through graph community detection, and generating LLM-based summaries of these communities to create a refined retrieval corpus.', 'Second, in contrast to static KG approaches (He et al., 2024; Edge et al., 2024), RAS dynamically constructs and evolves KGs based on the specific reasoning requirements of each query.', 'Recent efforts have explored integrating knowledge graphs (KGs) with LLMs (Sun et al., 2019; Yu et al., 2022; He et al., 2024; Edge et al., 2024), as KGs offer compact, structured representations of entities and relationships that enable more accurate and interpretable reasoning (Hogan et al.,…', '…constructs subgraphs by retrieving relevant entities and relations from a global KG, using these as structured knowledge input for LLMs. GraphRAG (Edge et al., 2024) employs an alternative strategy, extracting a comprehensive global KG from the corpus, identifying meaningful clusters through…'], 'sim_socre': 0.7599798222673898}\n",
      "{'title': 'VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos', 'abstract': 'Retrieval-Augmented Generation (RAG) has demonstrated remarkable success in enhancing Large Language Models (LLMs) through external knowledge integration, yet its application has primarily focused on textual content, leaving the rich domain of multi-modal video knowledge predominantly unexplored. This paper introduces VideoRAG, the first retrieval-augmented generation framework specifically designed for processing and understanding extremely long-context videos. Our core innovation lies in its dual-channel architecture that seamlessly integrates (i) graph-based textual knowledge grounding for capturing cross-video semantic relationships, and (ii) multi-modal context encoding for efficiently preserving visual features. This novel design empowers VideoRAG to process unlimited-length videos by constructing precise knowledge graphs that span multiple videos while maintaining semantic dependencies through specialized multi-modal retrieval paradigms. Through comprehensive empirical evaluation on our proposed LongerVideos benchmark-comprising over 160 videos totaling 134+ hours across lecture, documentary, and entertainment categories-VideoRAG demonstrates substantial performance compared to existing RAG alternatives and long video understanding methods. The source code of VideoRAG implementation and the benchmark dataset are openly available at: https://github.com/HKUDS/VideoRAG.', 'citationCount': 1, 'influentialCitationCount': 1, 'authors': [{'authorId': None, 'name': 'Xubin Ren'}, {'authorId': '2343886330', 'name': 'Lingrui Xu'}, {'authorId': '2287796033', 'name': 'Long Xia'}, {'authorId': '2237948548', 'name': 'Shuaiqiang Wang'}, {'authorId': '2261086768', 'name': 'Dawei Yin'}, {'authorId': '2344126030', 'name': 'Chao Huang'}], 'publicationDate': '2025-02-03', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['The first protocol, Win-Rate Comparison , follows established Retrieval-Augmented Generation (RAG) evaluation methodologies [11, 12] using LLM-based judgment.', 'Following the framework established in [11], our evaluation encompasses multiple dimensions for comprehensive analysis, focusing on five distinct aspects detailed as follows: We implement two key strategies to ensure reliable results.', 'In parallel, graph-based methods [11, 12, 22] have explored the use of structured knowledge representations to enhance the efficiency and precision of the retrieval process.', '(iii) Chunk Selection : Following entity matching, we apply a GraphRAG [11]-based methodology to sort and identify the most pertinent chunks H q from the retrieved collection.', '• GraphRAG [11] : An enhanced RAG system that that leverages LLMs to construct entity knowledge graphs from input documents.'], 'sim_socre': 0.7243294884862985}\n",
      "{'title': 'FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data', 'abstract': \"Prior research on training grounded factuality classification models to detect hallucinations in large language models (LLMs) has relied on public natural language inference (NLI) data and synthetic data. However, conventional NLI datasets are not well-suited for document-level reasoning, which is critical for detecting LLM hallucinations. Recent approaches to document-level synthetic data generation involve iteratively removing sentences from documents and annotating factuality using LLM-based prompts. While effective, this method is computationally expensive for long documents and limited by the LLM's capabilities. In this work, we analyze the differences between existing synthetic training data used in state-of-the-art models and real LLM output claims. Based on our findings, we propose a novel approach for synthetic data generation, CG2C, that leverages multi-hop reasoning on context graphs extracted from documents. Our fact checker model, FactCG, demonstrates improved performance with more connected reasoning, using the same backbone models. Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark with much smaller model size.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '51924717', 'name': 'Deren Lei'}, {'authorId': '2257103324', 'name': 'Yaxi Li'}, {'authorId': '2342861618', 'name': 'Siyao Li'}, {'authorId': '2257445973', 'name': 'Mengya Hu'}, {'authorId': '2319451125', 'name': 'Rui Xu'}, {'authorId': '2342502124', 'name': 'Ken Archer'}, {'authorId': '2257343204', 'name': 'Mingyu Wang'}, {'authorId': '2256990615', 'name': 'Emily Ching'}, {'authorId': '2316861245', 'name': 'Alex Deng'}], 'publicationDate': '2025-01-28', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['To answer RQ1, we select the RAGTruth (Niu et al., 2024) validation dataset from the LLM-A GGRE F ACT benchmark (Tang et al., 2024a) for analysis, as it contains three recognized tasks with RAG settings: Question Answering (QA), Data-to-text Writing (Data2Text), and News Summarization (Summ).', 'Synthetic data in MiniCheck’s D2C dataset lean towards claims with fewer hops, while LLM-generated claims in RAGTruth tend to have higher ratios of 2-hop and 3-hop claims.', 'Same as RAGTruth claims, we do not further process the D2C claims and analyze them on a sentence-level basis as provided.', 'It includes 11 datasets, namely A GGRE F ACT -CNN, A GGRE F ACT -XSum (Tang et al., 2023), TofuEval-MediaS, TofuEval-MeetB(Tang et al., 2024b), WiCE (Kamoi et al., 2023), REVEAL (Jacovi et al., 2024), ClaimVerify (Liu et al., 2023a), FactCheck (Wang et al., 2023), EXPERTQA (Malaviya et al., 2024), LFQA (Chen et al., 2024) and RAGTruth (Niu et al., 2024).', 'We follow GraphRag’s (Edge et al., 2024) prompt-based approach to extract ⟨ entity, entity, relation ⟩ triples from doc , where the relation is a short sentence that describes how the two entities are connected based on the context of the document, which is non-directional.', 'We even found non-negligible amounts of claims with 4 or more reasoning hops in RAGTruth across all tasks, which are very limited in D2C.', 'RAGTruth (Niu et al., 2024) analyzes word-level hallucinations in various domains and tasks within the standard retrieval-augmented generation frameworks for LLM applications.', 'Graph RAG (Edge et al., 2024) utilized LLM generated graphs to improve the RAG system on global questions that target the entire text corpus.'], 'sim_socre': 0.6444352915023586}\n",
      "{'title': 'How to Mitigate Information Loss in Knowledge Graphs for GraphRAG: Leveraging Triple Context Restoration and Query-Driven Feedback', 'abstract': 'Knowledge Graph (KG)-augmented Large Language Models (LLMs) have recently propelled significant advances in complex reasoning tasks, thanks to their broad domain knowledge and contextual awareness. Unfortunately, current methods often assume KGs to be complete, which is impractical given the inherent limitations of KG construction and the potential loss of contextual cues when converting unstructured text into entity-relation triples. In response, this paper proposes the Triple Context Restoration and Query-driven Feedback (TCR-QF) framework, which reconstructs the textual context underlying each triple to mitigate information loss, while dynamically refining the KG structure by iteratively incorporating query-relevant missing knowledge. Experiments on five benchmark question-answering datasets substantiate the effectiveness of TCR-QF in KG and LLM integration, where itachieves a 29.1% improvement in Exact Match and a 15.5% improvement in F1 over its state-of-the-art GraphRAG competitors.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2316952919', 'name': 'Manzong Huang'}, {'authorId': '2295417127', 'name': 'Chenyang Bu'}, {'authorId': '2283058074', 'name': 'Yi He'}, {'authorId': '2328264271', 'name': 'Xindong Wu'}], 'publicationDate': '2025-01-26', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': ['(4) Hybrid RAG : Methods like GraphRAG [Edge et al. , 2024] that retrieve information from both KG and textual documents to augment LLM. Experimental Settings: For all comparison meth-ods and the TCR-QF, unless otherwise specified, the gpt-4o-mini-2024-07-18 model was utilized, as it is more…', '…integration strategy involves retrieving relational data from a constructed KG and feed it into LLMs via prompt augmentation [Peng et al. , 2024; Sun et al. , 2023; Edge et al. , 2024], assuming that critical entities and relationships relevant to the query are already captured within the KG.'], 'sim_socre': 0.785827279529111}\n",
      "{'title': 'CG-RAG: Research Question Answering by Citation Graph Retrieval-Augmented LLMs', 'abstract': 'Research question answering requires accurate retrieval and contextual understanding of scientific literature. However, current Retrieval-Augmented Generation (RAG) methods often struggle to balance complex document relationships with precise information retrieval. In this paper, we introduce Contextualized Graph Retrieval-Augmented Generation (CG-RAG), a novel framework that integrates sparse and dense retrieval signals within graph structures to enhance retrieval efficiency and subsequently improve generation quality for research question answering. First, we propose a contextual graph representation for citation graphs, effectively capturing both explicit and implicit connections within and across documents. Next, we introduce Lexical-Semantic Graph Retrieval (LeSeGR), which seamlessly integrates sparse and dense retrieval signals with graph encoding. It bridges the gap between lexical precision and semantic understanding in citation graph retrieval, demonstrating generalizability to existing graph retrieval and hybrid retrieval methods. Finally, we present a context-aware generation strategy that utilizes the retrieved graph-structured information to generate precise and contextually enriched responses using large language models (LLMs). Extensive experiments on research question answering benchmarks across multiple domains demonstrate that our CG-RAG framework significantly outperforms RAG methods combined with various state-of-the-art retrieval approaches, delivering superior retrieval accuracy and generation quality.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2257349205', 'name': 'Yuntong Hu'}, {'authorId': '2303415589', 'name': 'Zhihan Lei'}, {'authorId': '2342896295', 'name': 'Zhongjie Dai'}, {'authorId': '2275878297', 'name': 'Allen Zhang'}, {'authorId': '2142231513', 'name': 'Abhinav Angirekula'}, {'authorId': '2021011947', 'name': 'Zhengwu Zhang'}, {'authorId': '2257314969', 'name': 'Liang Zhao'}], 'publicationDate': '2025-01-25', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': [], 'sim_socre': 0.8189052833924394}\n",
      "{'title': 'A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models', 'abstract': 'Large language models (LLMs) have demonstrated remarkable capabilities in a wide range of tasks, yet their application to specialized domains remains challenging due to the need for deep expertise. Retrieval-augmented generation (RAG) has emerged as a promising solution to customize LLMs for professional fields by seamlessly integrating external knowledge bases, enabling real-time access to domain-specific expertise during inference. Despite its potential, traditional RAG systems, based on flat text retrieval, face three critical challenges: (i) complex query understanding in professional contexts, (ii) difficulties in knowledge integration across distributed sources, and (iii) system efficiency bottlenecks at scale. This survey presents a systematic analysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new paradigm that revolutionizes domain-specific LLM applications. GraphRAG addresses traditional RAG limitations through three key innovations: (i) graph-structured knowledge representation that explicitly captures entity relationships and domain hierarchies, (ii) efficient graph-based retrieval techniques that enable context-preserving knowledge retrieval with multihop reasoning ability, and (iii) structure-aware knowledge integration algorithms that leverage retrieved knowledge for accurate and logical coherent generation of LLMs. In this survey, we systematically analyze the technical foundations of GraphRAG and examine current implementations across various professional domains, identifying key technical challenges and promising research directions. All the related resources of GraphRAG, including research papers, open-source data, and projects, are collected for the community in \\\\textcolor{blue}{\\\\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.', 'citationCount': 2, 'influentialCitationCount': 0, 'authors': [{'authorId': '2172162773', 'name': 'Qinggang Zhang'}, {'authorId': '2261365465', 'name': 'Shengyuan Chen'}, {'authorId': '2155460174', 'name': 'Yuan-Qi Bei'}, {'authorId': None, 'name': 'Zheng Yuan'}, {'authorId': '1962337917', 'name': 'Huachi Zhou'}, {'authorId': '2284697172', 'name': 'Zijin Hong'}, {'authorId': '2171902940', 'name': 'Junnan Dong'}, {'authorId': '2273742614', 'name': 'Hao Chen'}, {'authorId': '2342359893', 'name': 'Yi Chang'}, {'authorId': '2263873098', 'name': 'Xiao Huang'}], 'publicationDate': '2025-01-21', 'year': 2025, 'isInfluential': True, 'intents': [], 'contexts': ['To address these limitations, graph retrieval-augmented generation (GraphRAG) has recently emerged as a new paradigm to customize LLMs with well-organized background knowledge and improved contextual reasoning [25], [27]–[29].', '…analyze several critical limitations of existing GraphRAG systems regarding knowledge quality, knowledge conflict, data privacy, and efficiency RAG [25] General Domain Graph Construction, QA - Podcast Transcripts, News Articles ToG [22] General Domain QA WebQSP, CWQ Freebase ToG 2.0 [23] General…', 'In the general domain , GraphRAG models such as Graph RAG [25], SubgraphRAG [46], and StructRAG [14] are designed to handle tasks that require broad contextual understanding.', '…information and domain-specific terms are usually sparsely distributed across diverse knowledge carriers, the retrieval module of RAG systems often needs to search through a vast amount of unstructured text to find relevant information, requiring considerable computational resources and time [25].', 'RAG systems can be computationally expensive and time-consuming [25], especially when dealing with large-scale knowledge sources, as the model needs to search through vast amounts of unstructured text to find relevant information.', 'Moreover, approaches like GraphRAG [25] and GraphReader [40], which leverage LLMs for knowledge summarization, face additional challenges due to the high computational costs associated with LLMs.', 'The entire RAG pipeline - from initial corpus preprocessing and indexing to real-time retrieval and generation - faces significant efficiency bottlenecks [25], [26].', 'StructRAG [14], GraphRAG [25], LightRAG [26], QUEST [39], GraphReader [40], Structure-guided Prompts [41] GraphRAG with Existing Knowledge Graphs Fig.', 'To offer more informative knowledge augmentation, QUEST [39], GraphRAG [25], and GraphReader [40] construct attributed KGs where nodes are enriched with side information.'], 'sim_socre': 0.8289117023206805}\n",
      "{'title': 'MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation', 'abstract': \"The growing demand for efficient and lightweight Retrieval-Augmented Generation (RAG) systems has highlighted significant challenges when deploying Small Language Models (SLMs) in existing RAG frameworks. Current approaches face severe performance degradation due to SLMs' limited semantic understanding and text processing capabilities, creating barriers for widespread adoption in resource-constrained scenarios. To address these fundamental limitations, we present MiniRAG, a novel RAG system designed for extreme simplicity and efficiency. MiniRAG introduces two key technical innovations: (1) a semantic-aware heterogeneous graph indexing mechanism that combines text chunks and named entities in a unified structure, reducing reliance on complex semantic understanding, and (2) a lightweight topology-enhanced retrieval approach that leverages graph structures for efficient knowledge discovery without requiring advanced language capabilities. Our extensive experiments demonstrate that MiniRAG achieves comparable performance to LLM-based methods even when using SLMs while requiring only 25\\\\% of the storage space. Additionally, we contribute a comprehensive benchmark dataset for evaluating lightweight RAG systems under realistic on-device scenarios with complex queries. We fully open-source our implementation and datasets at: https://github.com/HKUDS/MiniRAG.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2339901253', 'name': 'Tianyu Fan'}, {'authorId': '2258762376', 'name': 'Jingyuan Wang'}, {'authorId': '2163180478', 'name': 'Xubin Ren'}, {'authorId': '2267495157', 'name': 'Chao Huang'}], 'publicationDate': '2025-01-12', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': ['Some prior RAG methods utilize LLMs to expand or decompose the query into fine-grained queries (Chan et al., 2024; Edge et al., 2024a; Guo et al., 2024), enhancing the match between the query and the index data.'], 'sim_socre': 0.7416663912668355}\n",
      "{'title': 'Graph-based Retrieval Augmented Generation for Dynamic Few-shot Text Classification', 'abstract': 'Text classification is a fundamental task in data mining, pivotal to various applications such as tabular understanding and recommendation. Although neural network-based models, such as CNN and BERT, have demonstrated remarkable performance in text classification, their effectiveness heavily relies on abundant labeled training data. This dependency makes these models less effective in dynamic few-shot text classification, where labeled data is scarce, and new target labels frequently appear based on application needs. Recently, large language models (LLMs) have shown promise due to their extensive pretraining and contextual understanding ability. Current approaches provide LLMs with text inputs, candidate labels, and additional side information (e.g., descriptions) to classify texts. However, their effectiveness is hindered by the increased input size and the noise introduced through side information processing. To address these limitations, we propose a graph-based online retrieval-augmented generation framework, namely GORAG, for dynamic few-shot text classification. Rather than treating each input independently, GORAG constructs and maintains a weighted graph by extracting side information across all target texts. In this graph, text keywords and labels are represented as nodes, with edges indicating the correlations between them. To model these correlations, GORAG employs an edge weighting mechanism to prioritize the importance and reliability of extracted information and dynamically retrieves relevant context using a minimum-cost spanning tree tailored for each text input. Empirical evaluations demonstrate that GORAG outperforms existing approaches by providing more comprehensive and precise contextual information.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2304518857', 'name': 'Yubo Wang'}, {'authorId': '2145537904', 'name': 'Haoyang Li'}, {'authorId': '2303256792', 'name': 'Fei Teng'}, {'authorId': '2302322072', 'name': 'Lei Chen'}], 'publicationDate': '2025-01-06', 'year': 2025, 'isInfluential': False, 'intents': [], 'contexts': [], 'sim_socre': 0.7551937292895305}\n",
      "{'title': 'Empowering Large Language Model Reasoning : Hybridizing Layered Retrieval Augmented Generation and Knowledge Graph Synthesis', 'abstract': ': Retrieval Augmented Generation has improved LLM question answering significantly. However, this mechanism still produces hallucinations and structural incoherence in knowledge-intensive tasks. Additionally, many existing techniques neither holistically leverage multiple properties of text nor integrate diverse prompting and agenting frameworks. To address these limitations, this paper proposes a novel methodology that extracts and utilizes unstructured and structured properties of text to construct layered RAG pipelines designed to enhance complex LLM reasoning. Our approach synthesizes three distinct RAG methodologies, each specialized in various aspects: textual entity knowledge graph extraction (Textual Entity RAG); community summary and entity generation (Microsoft GraphRAG), and structural link navigation (MetaWiki RAG). By cumulatively layering these techniques along with advanced prompting and agentic evaluation, we aim to capture a more comprehensive context, enabling the model to generate well-structured responses that reflect all relevant attributes of the text. The proposed framework not only enhances existing RAG mechanisms but also demonstrates the effective integration of knowledge graphs. Additionally, it showcases the application of this framework to advanced answer generation using Wikipedia, with extensions to similar knowledge networks. This novel approach offers a robust solution for social recommender systems and other practical applications, delivering holistic outcomes by synthesizing diverse RAG techniques.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2342410931', 'name': 'Vedanth Aggarwal'}], 'publicationDate': '2024-12-31', 'year': 2024, 'isInfluential': True, 'intents': [], 'contexts': ['13 Microsoft graph RAG also uses the dual search strategy that enables global search, which provides general, broader and high level information like themes, and local searches, which focus on specific entities and particular relationships such as character traits.', '13 Finally, most retrievals are unable to extract inherent connections in text i.e identify key relationships between major entities organized in information networks.', '13 Therefore, to solve this there is a growing interest in knowledge grounded generation.'], 'sim_socre': 0.8099273756574178}\n",
      "{'title': \"KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation\", 'abstract': \"Large language models (LLMs) demonstrate exceptional performance across a variety of tasks, yet they are often affected by hallucinations and the timeliness of knowledge. Leveraging knowledge graphs (KGs) as external knowledge sources has emerged as a viable solution, but existing methods for LLM-based knowledge graph question answering (KGQA) are often limited by step-by-step decision-making on KGs, restricting the global planning and reasoning capabilities of LLMs, or they require fine-tuning or pre-training on specific KGs. To address these challenges, we propose Knowledge graph Assisted Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global planning abilities of LLMs for efficient and accurate KG reasoning. KARPA operates in three steps: pre-planning relation paths using the LLM's global planning capabilities, matching semantically relevant paths via an embedding model, and reasoning over these paths to generate answers. Unlike existing KGQA methods, KARPA avoids stepwise traversal, requires no additional training, and is adaptable to various LLM architectures. Extensive experimental results show that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both high efficiency and accuracy. Our code will be available on Github.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2338362468', 'name': 'Siyuan Fang'}, {'authorId': '2281290823', 'name': 'Kaijing Ma'}, {'authorId': '2268491856', 'name': 'Tianyu Zheng'}, {'authorId': '2279346001', 'name': 'Xinrun Du'}, {'authorId': '2337804133', 'name': 'Ningxuan Lu'}, {'authorId': '2337820398', 'name': 'Ge Zhang'}, {'authorId': '2337855655', 'name': 'Qingkun Tang'}], 'publicationDate': '2024-12-30', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['KnowledgeNavigator (Guo et al., 2024) employs an iterative process where the LLM retrieves and filters relevant knowledge directly from the KG. GraphRAG (Edge et al., 2024) designs a powerful process that extracts structured data from unstructured text using LLMs.'], 'sim_socre': 0.7123798560865422}\n",
      "{'title': 'DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation', 'abstract': 'Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim to enhance language understanding and generation by leveraging external knowledge. However, effectively capturing and integrating the rich semantic information present in textual and structured data remains a challenge. To address this, a novel GRAG framework, Dynamic Graph Retrieval-Agumented Generation (DynaGRAG), is proposed to focus on enhancing subgraph representation and diversity within the knowledge graph. By improving graph density, capturing entity and relation information more effectively, and dynamically prioritizing relevant and diverse subgraphs and information within them, the proposed approach enables a more comprehensive understanding of the underlying semantic structure. This is achieved through a combination of de-duplication processes, two-step mean pooling of embeddings, query-aware retrieval considering unique nodes, and a Dynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating Graph Convolutional Networks (GCNs) and Large Language Models (LLMs) through hard prompting further enhances the learning of rich node and edge representations while preserving the hierarchical subgraph structure. Experimental results demonstrate the effectiveness of DynaGRAG, showcasing the significance of enhanced subgraph representation and diversity for improved language understanding and generation.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2337687519', 'name': 'Karishma Thakrar'}], 'publicationDate': '2024-12-24', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': [], 'sim_socre': 0.7969834064269736}\n",
      "{'title': 'Knowledge Graph Based Retrieval-Augmented Generation for Multi-Hop Question Answering Enhancement', 'abstract': \"Multi-hop question answering (QA), which requires integrating information from multiple sources, poses significant challenges in natural language processing. Existing methods often struggle with effective retrieval across documents, leading to incomplete or inaccurate answers. Building upon Graph-based Retrieval-Augmented Generation (Graph RAG), we enhance multi-hop QA by leveraging structured knowledge graphs. Specifically, we construct individual knowledge graphs for each document, where entities are represented as nodes and the relationships between them as edges enriched with contextual properties. These individual graphs are then seamlessly integrated into a comprehensive, unified graph that captures cross-document relationships. Our method improves retrieval by utilizing vector embeddings of these graph relations, enabling more effective multi-hop reasoning across the interconnected data. To evaluate our approach, we assembled a dataset of 500 documents paired with 296 multi-hop questions requiring cross-document information retrieval. Our contributions include developing a novel graph-based retrieval mechanism that leverages vector embeddings of graph relations within the Graph RAG framework, and assembling a comprehensive dataset for multi-hop QA. Comparative experiments show that our enhanced Graph RAG method significantly outperforms the baseline in factual accuracy and semantic similarity, as measured by the RAGAS framework. Additionally, an LLM-based evaluator highlights our method's superior performance in answer comprehensiveness, empowerment, and directness.11The source code and dataset are available at: https://github.com/AmiriShavaki/KG-based-RAG-for-Multi-hop-QA\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2347376532', 'name': 'Mahdi Amiri Shavaki'}, {'authorId': '2220062271', 'name': 'Pouria Omrani'}, {'authorId': '81287136', 'name': 'Ramin Toosi'}, {'authorId': '1697566', 'name': 'M. Akhaee'}], 'publicationDate': '2024-12-24', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['2) LLM Evaluator: In addition to RAGAS, we employed an LLM Evaluator based on a head-to-head comparison methodology, inspired by the approach used in [28].'], 'sim_socre': 0.8096712222821896}\n",
      "{'title': 'HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases', 'abstract': 'Given a semi-structured knowledge base (SKB), where text documents are interconnected by relations, how can we effectively retrieve relevant information to answer user questions? Retrieval-Augmented Generation (RAG) retrieves documents to assist large language models (LLMs) in question answering; while Graph RAG (GRAG) uses structured knowledge bases as its knowledge source. However, many questions require both textual and relational information from SKB - referred to as\"hybrid\"questions - which complicates the retrieval process and underscores the need for a hybrid retrieval method that leverages both information. In this paper, through our empirical analysis, we identify key insights that show why existing methods may struggle with hybrid question answering (HQA) over SKB. Based on these insights, we propose HybGRAG for HQA consisting of a retriever bank and a critic module, with the following advantages: (1) Agentic, it automatically refines the output by incorporating feedback from the critic module, (2) Adaptive, it solves hybrid questions requiring both textual and relational information with the retriever bank, (3) Interpretable, it justifies decision making with intuitive refinement path, and (4) Effective, it surpasses all baselines on HQA benchmarks. In experiments on the STaRK benchmark, HybGRAG achieves significant performance gains, with an average relative improvement in Hit@1 of 51%.', 'citationCount': 1, 'influentialCitationCount': 0, 'authors': [{'authorId': '151121638', 'name': 'Meng-Chieh Lee'}, {'authorId': '2299062897', 'name': 'Qi Zhu'}, {'authorId': '2336865777', 'name': 'C. Mavromatis'}, {'authorId': '2337234732', 'name': 'Zhen Han'}, {'authorId': '2121390172', 'name': 'Soji Adeshina'}, {'authorId': '40043851', 'name': 'V. Ioannidis'}, {'authorId': '145344187', 'name': 'H. Rangwala'}, {'authorId': '2263543517', 'name': 'Christos Faloutsos'}], 'publicationDate': '2024-12-20', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['The second focuses on ODQA, building relationships between documents to improve retrieval (Li et al., 2024a; Dong et al., 2024; Edge et al., 2024).', '…leverages LLMs for Knowledge Base Question Answering (KBQA) (Yasunaga et al., 2021; Sun et al., 2024; Jin et al., 2024; Mavro-matis and Karypis, 2024), and building relationships between documents in the database to improve ODQA performance (Li et al., 2024a; Dong et al., 2024; Edge et al., 2024).'], 'sim_socre': 0.7656661692911007}\n",
      "{'title': 'SEAGraph: Unveiling the Whole Story of Paper Review Comments', 'abstract': \"Peer review, as a cornerstone of scientific research, ensures the integrity and quality of scholarly work by providing authors with objective feedback for refinement. However, in the traditional peer review process, authors often receive vague or insufficiently detailed feedback, which provides limited assistance and leads to a more time-consuming review cycle. If authors can identify some specific weaknesses in their paper, they can not only address the reviewer's concerns but also improve their work. This raises the critical question of how to enhance authors' comprehension of review comments. In this paper, we present SEAGraph, a novel framework developed to clarify review comments by uncovering the underlying intentions behind them. We construct two types of graphs for each paper: the semantic mind graph, which captures the author's thought process, and the hierarchical background graph, which delineates the research domains related to the paper. A retrieval method is then designed to extract relevant content from both graphs, facilitating coherent explanations for the review comments. Extensive experiments show that SEAGraph excels in review comment understanding tasks, offering significant benefits to authors.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2198507600', 'name': 'Jianxiang Yu'}, {'authorId': '2258774994', 'name': 'Jiaqi Tan'}, {'authorId': '2284245211', 'name': 'Zichen Ding'}, {'authorId': '2274978444', 'name': 'Jiapeng Zhu'}, {'authorId': '2335808698', 'name': 'Jiahao Li'}, {'authorId': '2165643958', 'name': 'Yao Cheng'}, {'authorId': '2335671838', 'name': 'Qier Cui'}, {'authorId': '2284992645', 'name': 'Yunshi Lan'}, {'authorId': '2284260692', 'name': 'Xiang Li'}], 'publicationDate': '2024-12-16', 'year': 2024, 'isInfluential': True, 'intents': [], 'contexts': ['GraphRAG emerges as an innovative solution to address this challenge (Peng et al., 2024a).', 'Wu et al. (2024a) and Sepasdar et al. (2024) construct specialized knowledge graphs, extending GraphRAG to the medical and soccer domains.', 'Recently, the success of GraphRAG (Edge et al., 2024), which splits lengthy texts into discrete chunks and hierarchically connects them, has inspired new directions.', 'Edge et al. (2024) establish logical relationships between segments by connecting chunks or communities through a hierarchical structure.', 'In this work, we construct two logically connected graphs for the paper, leveraging the strengths of GraphRAG to better address the review comment understanding tasks.'], 'sim_socre': 0.6475988079828556}\n",
      "{'title': 'When Graph Meets Retrieval Augmented Generation for Wireless Networks: A Tutorial and Case Study', 'abstract': \"The rapid development of next-generation networking technologies underscores their transformative role in revolutionizing modern communication systems, enabling faster, more reliable, and highly interconnected solutions. However, such development has also brought challenges to network optimizations. Thanks to the emergence of Large Language Models (LLMs) in recent years, tools including Retrieval Augmented Generation (RAG) have been developed and applied in various fields including networking, and have shown their effectiveness. Taking one step further, the integration of knowledge graphs into RAG frameworks further enhanced the performance of RAG in networking applications such as Intent-Driven Networks (IDNs) and spectrum knowledge maps by providing more contextually relevant responses through more accurate retrieval of related network information. This paper introduces the RAG framework that integrates knowledge graphs in its database and explores such framework's application in networking. We begin by exploring RAG's applications in networking and the limitations of conventional RAG and present the advantages that knowledge graphs' structured knowledge representation brings to the retrieval and generation processes. Next, we propose a detailed GraphRAG-based framework for networking, including a step-by-step tutorial on its construction. Our evaluation through a case study on channel gain prediction demonstrates GraphRAG's enhanced capability in generating accurate, contextually rich responses, surpassing traditional RAG models. Finally, we discuss key future directions for applying knowledge-graphs-empowered RAG frameworks in networking, including robust updates, mitigation of hallucination, and enhanced security measures for networking applications.\", 'citationCount': 1, 'influentialCitationCount': 0, 'authors': [{'authorId': '2335456805', 'name': 'Yang Xiong'}, {'authorId': '2266463634', 'name': 'Ruichen Zhang'}, {'authorId': '2237948862', 'name': 'Yinqiu Liu'}, {'authorId': '1713586', 'name': 'D. Niyato'}, {'authorId': '2943819', 'name': 'Zehui Xiong'}, {'authorId': '2334748710', 'name': 'Ying-Chang Liang'}, {'authorId': '2237802924', 'name': 'Shiwen Mao'}], 'publicationDate': '2024-12-10', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['As a validation of GraphRAG’s advantages, experiments in [12] comparing GraphRAG and vanilla RAG on various generation tasks demonstrated that GraphRAG improves answer comprehensiveness, diversity, and empowerment by approximately 30%, producing more contextually helpful responses.', 'In addition to chunk size experimentation, we compared two frameworks by evaluating their responses to identical queries for optimization problem generation, using metrics from [12] and introducing “hallucinations\" to assess response faithfulness.'], 'sim_socre': 0.7587481635229183}\n",
      "{'title': 'TKG-RAG: A Retrieval-Augmented Generation Framework with Text-chunk Knowledge Graph', 'abstract': 'The approach of dividing text into chunks and building indexes is a mainstream approach for Retrieval-Augmented Generation (RAG) of Large Language Models (LLMs). However, retrieved text chunks often contain noise or redundant information, which can negatively impact RAG performance. To address this limitation, researchers have proposed RAG approaches based on text chunks, knowledge graphs, and long-texts. Nevertheless, there are still challenges that need to be addressed, such as the underutilization of knowledge within text chunks, the resource-intensive nature and complex process of constructing Knowledge Graphs (KG), and the lack of emphasis on optimization during the post-processing filtering stage. We propose a RAG framework with text-chunk knowledge graph (TKG-RAG). The proposed framework can construct a text-chunk knowledge graph automatically by extracting the hierarchical structure, contextual relationships, topic sentences, and inter-chunk relationships from the domain text. The framework begins by using text indexing to retrieve relevant text chunks based on similarity. These chunks are then mapped to nodes within the text-chunk knowledge graph, where connections are established based on the relationships of nodes in the graph to generate subgraphs. The content of the nodes is rearranged and merged using the hierarchical structure and relational knowledge in the graph, and then the residual isolated nodes that are not merged are fused based on the attribute knowledge in the TKG. In addition, to improve the performance of filters in the post-processing stage, we incorporate the datasets considering texts and numerical characteristics, into the fine-tuning process of the filter model. This approach aimed to enhance the accuracy of filtering and reduce token consumption in the generation stage. To validate the effectiveness of this approach, comparative and ablation experiments were conducted on five datasets: NQ, PopQA, HotpotQA, TriviaQA, and LawQA. The results show that TKG-RAG can achieve better performance in terms of Accuracy and F1 scores, while also reducing token consumption by 46%, means that TKG-RAG can combine the strengths of chunk-based and graph-based RAG approaches.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2347009525', 'name': 'Wei Xiao'}, {'authorId': '2146401380', 'name': 'Yu Liu'}, {'authorId': '2307485053', 'name': 'Xianglong Li'}, {'authorId': '2169808832', 'name': 'Feng Gao'}, {'authorId': '2239168053', 'name': 'Jinguang Gu'}], 'publicationDate': '2024-12-10', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': [], 'sim_socre': 0.8105885947613215}\n",
      "{'title': 'KG-Retriever: Efficient Knowledge Indexing for Retrieval-Augmented Large Language Models', 'abstract': 'Large language models with retrieval-augmented generation encounter a pivotal challenge in intricate retrieval tasks, e.g., multi-hop question answering, which requires the model to navigate across multiple documents and generate comprehensive responses based on fragmented information. To tackle this challenge, we introduce a novel Knowledge Graph-based RAG framework with a hierarchical knowledge retriever, termed KG-Retriever. The retrieval indexing in KG-Retriever is constructed on a hierarchical index graph that consists of a knowledge graph layer and a collaborative document layer. The associative nature of graph structures is fully utilized to strengthen intra-document and inter-document connectivity, thereby fundamentally alleviating the information fragmentation problem and meanwhile improving the retrieval efficiency in cross-document retrieval of LLMs. With the coarse-grained collaborative information from neighboring documents and concise information from the knowledge graph, KG-Retriever achieves marked improvements on five public QA datasets, showing the effectiveness and efficiency of our proposed RAG framework.', 'citationCount': 1, 'influentialCitationCount': 0, 'authors': [{'authorId': '2334493192', 'name': 'Weijie Chen'}, {'authorId': '2260482811', 'name': 'Ting Bai'}, {'authorId': '2335609031', 'name': 'Jinbo Su'}, {'authorId': '2257013742', 'name': 'Jian Luan'}, {'authorId': '2257333016', 'name': 'Wei Liu'}, {'authorId': '2328349476', 'name': 'Chuan Shi'}], 'publicationDate': '2024-12-07', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['Some researchers (Edge et al., 2024) have explored building graph-based texts to improve the performance of LLMs in Query-Focused Summarization.', 'These include using LLMs for knowledge graph creation (Trajanoska et al., 2023; Edge et al., 2024), completion (Yao et al., 2023), and knowledge editing citeshi2024retrieval.'], 'sim_socre': 0.817604827590067}\n",
      "{'title': 'Enhancing Document Retrieval Using AI and Graph-Based RAG Techniques', 'abstract': 'Retrieval-Augmented Generation (RAG) has emerged as a potent method for enhancing the capabilities of large language models (LLMs) by integrating them with external knowledge sources. While traditional RAG models rely heavily on textual similarity for retrieval, often leading to issues like context drift and hallucinations, graph-based RAG offers a more sophisticated approach. By representing documents and their relationships within a graph structure, graph-based RAG enables more context-aware retrieval, reducing hallucinations, and facilitating multi-hop reasoning. This abstract provides an overview of the RAG landscape, contrasting traditional and graph-based approaches, and highlights the advantages of graph-based RAG in addressing the limitations of traditional methods. The application of graph-based RAG to various domains, such as question answering, dialogue systems, and recommendation systems, is also explored. The abstract concludes by emphasizing the potential of graph-based RAG to revolutionize information access and retrieval in diverse AI applications.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '70080947', 'name': 'Vikas Kamra'}, {'authorId': '2347372802', 'name': 'Lakshya Gupta'}, {'authorId': '2304786954', 'name': 'Dhruv Arora'}, {'authorId': None, 'name': 'Ashwin Kumar Yadav'}], 'publicationDate': '2024-12-06', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['[16] These systems can be integrated into customer service chatbots, virtual assistants, or educational platforms to provide precise answers to user queries.'], 'sim_socre': 0.8171483007393693}\n",
      "{'title': 'Synergizing LLMs and Knowledge Graphs: A Novel Approach to Software Repository-Related Question Answering', 'abstract': 'Software repositories contain valuable information for gaining insights into their development process. However, extracting insights from these repository data is time-consuming and requires technical expertise. While software engineering chatbots have been developed to facilitate natural language interactions with repositories, they struggle with understanding natural language and accurately retrieving relevant data. This study aims to improve the accuracy of LLM-based chatbots in answering repository-related questions by augmenting them with knowledge graphs. We achieve this in a two-step approach; (1) constructing a knowledge graph from the repository data and (2) synergizing the knowledge graph with LLM to allow for the natural language questions and answers. We curated a set of 20 questions with different complexities and evaluated our approach on five popular open-source projects. Our approach achieved an accuracy of 65%. We further investigated the limitations and identified six key issues, with the majority relating to the reasoning capability of the LLM. We experimented with a few-shot chain-of-thought prompting to determine if it could enhance our approach. This technique improved the overall accuracy to 84%. Our findings demonstrate the synergy between LLMs and knowledge graphs as a viable solution for making repository data accessible to both technical and non-technical stakeholders.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2304795554', 'name': 'Samuel Abedu'}, {'authorId': '70044512', 'name': 'S. Khatoonabadi'}, {'authorId': '2065557640', 'name': 'Emad Shihab'}], 'publicationDate': '2024-12-05', 'year': 2024, 'isInfluential': True, 'intents': [], 'contexts': ['The end-to-end evaluation measures the practical performance of our approach in generating accurate answers [22].', 'Also, we followed a similar approach as the evaluation of RQ1; executing the experiments five times for each question to account for the stochastic nature of the LLMs generation [22].', 'Due to the stochastic nature of LLMs, we run the experiments five times, each time on a different repository [22].'], 'sim_socre': 0.6627391483894551}\n",
      "{'title': 'Improving Physics Reasoning in Large Language Models Using Mixture of Refinement Agents', 'abstract': 'Large Language Models (LLMs) demonstrate remarkable capabilities in various reasoning tasks. However, they encounter significant challenges when it comes to scientific reasoning, particularly in physics, which requires not only mathematical reasoning but also factual and conceptual understanding. When addressing complex physics problems, LLMs typically face three key issues: problem miscomprehension, incorrect concept application, and computational errors. While each of these problems can be addressed individually, there is a need for a generalized approach that can tackle all three issues simultaneously. To address this, we introduce Mixture of Refinement Agents (MoRA), a novel agentic refinement framework that iteratively refines the LLM generated base solution by correcting the aforementioned errors, resulting in a significant performance improvement for open-source LLMs. Our approach aims to bridge the gap between opensource LLMs and GPT-4o by utilizing the latter as error identifier to guide these refinement agents. We evaluate our approach on the SciEval and MMLU subsets along with our own physics dataset (PhysicsQA). MoRA significantly improves the performance of Llama-3-70B and Gemma-2-27B on these datasets, achieving up to a 16% increase in final answer accuracy.', 'citationCount': 2, 'influentialCitationCount': 0, 'authors': [{'authorId': '2261399651', 'name': 'Raj Jaiswal'}, {'authorId': '2333401854', 'name': 'Dhruv Jain'}, {'authorId': '2326123719', 'name': 'Harsh Popat'}, {'authorId': '2223123570', 'name': 'Avinash Anand'}, {'authorId': '2326128202', 'name': 'Abhishek Dharmadhikari'}, {'authorId': '2326126008', 'name': 'Atharva Marathe'}, {'authorId': '1753278', 'name': 'R. Shah'}], 'publicationDate': '2024-12-01', 'year': 2024, 'isInfluential': True, 'intents': [], 'contexts': ['A notable example is GraphRAG (Edge et al. 2024), a retrieval enhancement technique that leverages knowledge graphs to map relationships between entities, thereby enhancing the retrieval process using large language models (LLMs).', 'Given the response and concept verification score, LLM generates a retrieval thought, which acts as a query to retrieve the correct conceptual context from an physics knowledge base using GraphRAG. error tolerance of 0.1.', 'Concept Retrieval & Solution Refinement: Given the retrieval thought T R and physics knowledge base K P , we use GraphRAG (Edge et al., 2024) to query the K P to retrieve an observation O T , based on T R as demonstrated in Figure 2.'], 'sim_socre': 0.5983358366361803}\n",
      "{'title': 'Knowledge Management for Automobile Failure Analysis Using Graph RAG', 'abstract': 'This paper presents a knowledge management system for automobile failure analysis using retrieval-augmented generation (RAG) with large language models (LLMs) and knowledge graphs (KGs). In the automotive industry, there is a growing demand for knowledge transfer of failure analysis from experienced engineers to young engineers. However, failure events are phenomena that occur in a chain reaction, making them difficult for beginners to analyze them. While knowledge graphs, which can describe semantic relationships and structure information is effective in representing failure events, due to their capability of representing the relationships between components, there is much information in KGs, so it is challenging for young engineers to extract and understand sub-graphs from the KG. On the other hand, there is increasing interest in the use of Graph RAG, a type of RAG that combines LLMs and KGs for knowledge management. However, when using the current Graph RAG framework with an existing knowledge graph for automobile failures, several issues arise because it is difficult to generate executable queries for a knowledge graph database which is not constructed by LLMs. To address this, we focused on optimizing the Graph RAG pipeline for existing knowledge graphs. Using an original Q&A dataset, the ROUGE F1 score of the sentences generated by the proposed method showed an average improvement of 157.6% compared to the current method. This highlights the effectiveness of the proposed method for automobile failure analysis.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2333237478', 'name': 'Yuta Ojima'}, {'authorId': '2333236150', 'name': 'Hiroki Sakaji'}, {'authorId': '2333323194', 'name': 'Tadashi Nakamura'}, {'authorId': '2333236169', 'name': 'Hiroaki Sakata'}, {'authorId': '2333237537', 'name': 'Kazuya Seki'}, {'authorId': '2333236137', 'name': 'Yuu Teshigawara'}, {'authorId': '2212701761', 'name': 'Masami Yamashita'}, {'authorId': '2333237410', 'name': 'Kazuhiro Aoyama'}], 'publicationDate': '2024-11-29', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['This method answers user questions based on external information resources, and Graph RAG [5], which is a type of RAG that combines LLMs and KGs, enables responses to users’ queries based on the information within those graphs.', 'Microsoft has proposed a Graph RAG system as a RAG framework that utilizes knowledge graphs [5].'], 'sim_socre': 0.7698314571569077}\n",
      "{'title': 'Can LLMs be Good Graph Judger for Knowledge Graph Construction?', 'abstract': 'In real-world scenarios, most of the data obtained from information retrieval (IR) system is unstructured. Converting natural language sentences into structured Knowledge Graphs (KGs) remains a critical challenge. The quality of constructed KGs may also impact the performance of some KG-dependent domains like GraphRAG systems and recommendation systems. Recently, Large Language Models (LLMs) have demonstrated impressive capabilities in addressing a wide range of natural language processing tasks. However, there are still challenges when utilizing LLMs to address the task of generating structured KGs. And we have identified three limitations with respect to existing KG construction methods. (1)There is a large amount of information and excessive noise in real-world documents, which could result in extracting messy information. (2)Native LLMs struggle to effectively extract accuracy knowledge from some domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked when utilizing LLMs directly as an unsupervised method for constructing KGs. In this paper, we propose GraphJudger, a knowledge graph construction framework to address the aforementioned challenges. We introduce three innovative modules in our method, which are entity-centric iterative text denoising, knowledge aware instruction tuning and graph judgement, respectively. We seek to utilize the capacity of LLMs to function as a graph judger, a capability superior to their role only as a predictor for KG construction problems. Experiments conducted on two general text-graph pair datasets and one domain-specific text-graph pair dataset show superior performances compared to baseline methods. The code of our proposed method is available at https://github.com/hhy-huang/GraphJudger.', 'citationCount': 1, 'influentialCitationCount': 0, 'authors': [{'authorId': '2332517415', 'name': 'Haoyu Huang'}, {'authorId': '2309659454', 'name': 'Chong Chen'}, {'authorId': '2291040348', 'name': 'Conghui He'}, {'authorId': '2325803763', 'name': 'Yang Li'}, {'authorId': '2332512942', 'name': 'Jiawei Jiang'}, {'authorId': '2332448482', 'name': 'Wentao Zhang'}], 'publicationDate': '2024-11-26', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['Knowledge Graphs, which serve as the backbone of numerous data science applications, including GraphRAG systems [1] [2] and recommendation systems [3] [4], are becoming increasingly central to how we process and understand vast amounts of information.', 'For example, in the GraphRAG system [1], the KG construction strategy involves repeatedly querying the LLM after the initial generation round until the LLM determines that the correct answer has been produced.'], 'sim_socre': 0.7090112538514826}\n",
      "{'title': 'G-RAG: Knowledge Expansion in Material Science', 'abstract': 'In the field of Material Science, effective information retrieval systems are essential for facilitating research. Traditional Retrieval-Augmented Generation (RAG) approaches in Large Language Models (LLMs) often encounter challenges such as outdated information, hallucinations, limited interpretability due to context constraints, and inaccurate retrieval. To address these issues, Graph RAG integrates graph databases to enhance the retrieval process. Our proposed method processes Material Science documents by extracting key entities (referred to as MatIDs) from sentences, which are then utilized to query external Wikipedia knowledge bases (KBs) for additional relevant information. We implement an agent-based parsing technique to achieve a more detailed representation of the documents. Our improved version of Graph RAG called G-RAG further leverages a graph database to capture relationships between these entities, improving both retrieval accuracy and contextual understanding. This enhanced approach demonstrates significant improvements in performance for domains that require precise information retrieval, such as Material Science.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2331857304', 'name': 'Radeen Mostafa'}, {'authorId': '2331857016', 'name': 'Mirza Nihal Baig'}, {'authorId': '2331612416', 'name': 'Mashaekh Tausif Ehsan'}, {'authorId': '2331856921', 'name': 'Jakir Hasan'}], 'publicationDate': '2024-11-21', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['Additionally, researchers have introduced innovative graph-based context adaptation techniques that refine word embeddings to better capture semantic relationships, consistently outperforming traditional methods in various Natural Language Processing (NLP) tasks [4, 5].', 'While supplying an LLM with text chunks from extensive documents may result in issues with context, factual precision, and language coherence, Graph RAG addresses these limitations by utilizing a knowledge graph as a source of structured, factual information [5].'], 'sim_socre': 0.7794968042194769}\n",
      "{'title': 'Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models', 'abstract': \"Narrative data spans all disciplines and provides a coherent model of the world to the reader or viewer. Recent advancement in machine learning and Large Language Models (LLMs) have enable great strides in analyzing natural language. However, Large language models (LLMs) still struggle with complex narrative arcs as well as narratives containing conflicting information. Recent work indicates LLMs augmented with external knowledge bases can improve the accuracy and interpretability of the resulting models. In this work, we analyze the effectiveness of applying knowledge graphs (KGs) in understanding true-crime podcast data from both classical Natural Language Processing (NLP) and LLM approaches. We directly compare KG-augmented LLMs (KGLLMs) with classical methods for KG construction, topic modeling, and sentiment analysis. Additionally, the KGLLM allows us to query the knowledge base in natural language and test its ability to factually answer questions. We examine the robustness of the model to adversarial prompting in order to test the model's ability to deal with conflicting information. Finally, we apply classical methods to understand more subtle aspects of the text such as the use of hearsay and sentiment in narrative construction and propose future directions. Our results indicate that KGLLMs outperform LLMs on a variety of metrics, are more robust to adversarial prompts, and are more capable of summarizing the text into topics.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2329189844', 'name': 'Xinyi Leng'}, {'authorId': '2329314936', 'name': 'Jason Liang'}, {'authorId': '2329188642', 'name': 'Jack Mauro'}, {'authorId': '2329309885', 'name': 'Xu Wang'}, {'authorId': '2267332568', 'name': 'Andrea L. Bertozzi'}, {'authorId': '2329183873', 'name': 'James Chapman'}, {'authorId': '2267386664', 'name': 'Junyuan Lin'}, {'authorId': '2152691135', 'name': 'Bohan Chen'}, {'authorId': '2330066785', 'name': 'Chenchen Ye'}, {'authorId': '2329191994', 'name': 'Temple Daniel'}, {'authorId': '1970636', 'name': 'P. Brantingham'}], 'publicationDate': '2024-11-01', 'year': 2024, 'isInfluential': True, 'intents': ['background', 'methodology'], 'contexts': ['GraphRAG [13] is an automated way to build a knowledge graph, using an LLM to extract relations from the text.', 'GraphRAG implements both a local and global retrieval mechanism for querying the KG. Local retrieval is designed for specific question answering, whereas global retrieval is designed for more abstract reasoning about the text [13].', 'A hierarchical knowledge graph 𝐺 = (E , R , C) is a knowledge graph with a set C that encodes a hierarchical clustering of the nodes in the graph [13].', 'In this work, we focus on GraphRAG which performs both knowledge graph construction and retrieval [13].', 'The chunk size was adjusted because [13] suggests 600 is an optimal chunk size for entity extraction and the base models were chosen to reduce experimentation costs.', 'This deviates from similar work in applying KGLLMs where the dataset is consistent with itself and the data is generally trustworthy [9, 13].', 'Responses from these models are evaluated by a separate LLM called an evaluator , as laid out in Edge et al. [13].', 'Our exploration of the graph revealed short-comings of this approach, so we use GraphRAG [13] for an LLM enhanced knowledge graph construction pipeline.'], 'sim_socre': 0.6729834360976485}\n",
      "{'title': 'EmbodiedRAG: Dynamic 3D Scene Graph Retrieval for Efficient and Scalable Robot Task Planning', 'abstract': \"Recent advances in Large Language Models (LLMs) have helped facilitate exciting progress for robotic planning in real, open-world environments. 3D scene graphs (3DSGs) offer a promising environment representation for grounding such LLM-based planners as they are compact and semantically rich. However, as the robot's environment scales (e.g., number of entities tracked) and the complexity of scene graph information increases (e.g., maintaining more attributes), providing the 3DSG as-is to an LLM-based planner quickly becomes infeasible due to input token count limits and attentional biases present in LLMs. Inspired by the successes of Retrieval-Augmented Generation (RAG) methods that retrieve query-relevant document chunks for LLM question and answering, we adapt the paradigm for our embodied domain. Specifically, we propose a 3D scene subgraph retrieval framework, called EmbodiedRAG, that we augment an LLM-based planner with for executing natural language robotic tasks. Notably, our retrieved subgraphs adapt to changes in the environment as well as changes in task-relevancy as the robot executes its plan. We demonstrate EmbodiedRAG's ability to significantly reduce input token counts (by an order of magnitude) and planning time (up to 70% reduction in average time per planning step) while improving success rates on AI2Thor simulated household tasks with a single-arm, mobile manipulator. Additionally, we implement EmbodiedRAG on a quadruped with a manipulator to highlight the performance benefits for robot deployment at the edge in real environments.\", 'citationCount': 1, 'influentialCitationCount': 0, 'authors': [{'authorId': '2325097355', 'name': 'Meghan Booker'}, {'authorId': '2322094909', 'name': 'Grayson Byrd'}, {'authorId': '2325095950', 'name': 'Bethany Kemp'}, {'authorId': '2325941161', 'name': 'Aurora Schmidt'}, {'authorId': '2248051659', 'name': 'Corban Rivera'}], 'publicationDate': '2024-10-31', 'year': 2024, 'isInfluential': False, 'intents': ['background', 'methodology'], 'contexts': ['The retrieved entities serve as entry points into our 3DSG, similar to how the local search component in graphRAG [30] gains access to a knowledge graph.', 'Since then many techniques and adaptations have been introduced such as pre-retrieval query rewriting [28], iterative knowledge retrieval [29], and extensions to knowledge graph structures [30].'], 'sim_socre': 0.7302976309026851}\n",
      "{'title': 'GraphAide: Advanced Graph-Assisted Query and Reasoning System', 'abstract': 'Curating knowledge from multiple siloed sources that contain both structured and unstructured data is a major challenge in many real-world applications. Pattern matching and querying represent fundamental tasks in modern data analytics that leverage this curated knowledge. The development of such applications necessitates overcoming several research challenges, including data extraction, named entity recognition, data modeling, and designing query interfaces. Moreover, the explainability of these functionalities is critical for their broader adoption.The emergence of Large Language Models (LLMs) has accelerated the development lifecycle of new capabilities. Nonetheless, there is an ongoing need for domain-specific tools tailored to user activities. The creation of such digital assistants has gained considerable traction in recent years, with LLMs offering a promising avenue to develop such assistants utilizing domain-specific knowledge and assumptions.In this context, we introduce an advanced query and reasoning system, GraphAide, which constructs a knowledge graph (KG) from diverse sources and allows to query and reason over the resulting KG. GraphAide harnesses both the KG and LLMs to rapidly develop domain-specific digital assistants. It integrates design patterns from retrieval augmented generation (RAG) and the semantic web to create an agentic LLM application. GraphAide underscores the potential for streamlined and efficient development of specialized digital assistants, thereby enhancing their applicability across various domains.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '1950842', 'name': 'Sumit Purohit'}, {'authorId': '2330401153', 'name': 'George Chin'}, {'authorId': '2330400951', 'name': 'Patrick Mackey'}, {'authorId': '2049027', 'name': 'Joseph A. Cottam'}], 'publicationDate': '2024-10-29', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['GraphRAG Edge et al. (2024) advances this field by presenting a query-focused summarization task (QFS) that builds efficient text indices over a KG. GraphRAG leverages community detection to partition the graph index and uses it to generate ”global answers” to user queries.'], 'sim_socre': 0.7782612336183162}\n",
      "{'title': 'Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation', 'abstract': \"Large Language Models (LLMs) demonstrate strong reasoning abilities but face limitations such as hallucinations and outdated knowledge. Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by grounding LLM outputs in structured external knowledge from KGs. However, current KG-based RAG frameworks still struggle to optimize the trade-off between retrieval effectiveness and efficiency in identifying a suitable amount of relevant graph information for the LLM to digest. We introduce SubgraphRAG, extending the KG-based RAG framework that retrieves subgraphs and leverages LLMs for reasoning and answer prediction. Our approach innovatively integrates a lightweight multilayer perceptron with a parallel triple-scoring mechanism for efficient and flexible subgraph retrieval while encoding directional structural distances to enhance retrieval effectiveness. The size of retrieved subgraphs can be flexibly adjusted to match the query's need and the downstream LLM's capabilities. This design strikes a balance between model complexity and reasoning power, enabling scalable and generalizable retrieval processes. Notably, based on our retrieved subgraphs, smaller LLMs like Llama3.1-8B-Instruct deliver competitive results with explainable reasoning, while larger models like GPT-4o achieve state-of-the-art accuracy compared with previous baselines -- all without fine-tuning. Extensive evaluations on the WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency, accuracy, and reliability by reducing hallucinations and improving response grounding.\", 'citationCount': 4, 'influentialCitationCount': 0, 'authors': [{'authorId': '2112144150', 'name': 'Mufei Li'}, {'authorId': '2151793768', 'name': 'Siqi Miao'}, {'authorId': '2328306177', 'name': 'Pan Li'}], 'publicationDate': '2024-10-28', 'year': 2024, 'isInfluential': False, 'intents': ['background'], 'contexts': ['Recent studies have explored using graph-structured knowledge, particularly knowledge graphs (KGs), as external resources for RAG (Pan et al., 2024; Peng et al., 2024; Edge et al., 2024).'], 'sim_socre': 0.7862937246247323}\n",
      "{'title': 'An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&A Platforms', 'abstract': \"Question Answering (QA) systems face challenges in handling complex questions that require multi-domain knowledge synthesis. The naive RAG models, although effective in information retrieval, struggle with complex questions that require comprehensive and in-depth answers. The pioneering task is defined as explanatory answer generation, which entails handling identified challenges such as the requirement for comprehensive information and logical coherence within the generated context. To address these issues, we refer to systematic thinking theory and propose SynthRAG, an innovative framework designed to enhance QA performance. SynthRAG improves on conventional models by employing adaptive outlines for dynamic content structuring, generating systematic information to ensure detailed coverage, and producing customized answers tailored to specific user inquiries. This structured approach guarantees logical coherence and thorough integration of information, yielding responses that are both insightful and methodically organized. Empirical evaluations underscore SynthRAG's effectiveness, demonstrating its superiority in handling complex questions, overcoming the limitations of naive RAG models, and significantly improving answer quality and depth. Furthermore, an online deployment on the Zhihu platform revealed that SynthRAG's answers achieved notable user engagement, with each response averaging 5.73 upvotes and surpassing the performance of 79.8% of human contributors, highlighting the practical relevance and impact of the proposed framework. Our code is available at https://github.com/czy1999/SynthRAG .\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2117098298', 'name': 'Ziyang Chen'}, {'authorId': '2108114693', 'name': 'Xiaobin Wang'}, {'authorId': '2256747040', 'name': 'Yong Jiang'}, {'authorId': '9387602', 'name': 'Jinzhi Liao'}, {'authorId': '35930962', 'name': 'Pengjun Xie'}, {'authorId': '2276428076', 'name': 'Fei Huang'}, {'authorId': '2327289650', 'name': 'Xiang Zhao'}], 'publicationDate': '2024-10-23', 'year': 2024, 'isInfluential': False, 'intents': ['background'], 'contexts': ['GraphRAG [7] provides a global perspective for LLMs by constructing a knowledge graph, enhancing the quality of responses effectively.'], 'sim_socre': 0.7197176096686703}\n",
      "{'title': 'Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective', 'abstract': 'Knowledge Graphs (KGs) are crucial in the field of artificial intelligence and are widely used in downstream tasks, such as question-answering (QA). The construction of KGs typically requires significant effort from domain experts. Large Language Models (LLMs) have recently been used for Knowledge Graph Construction (KGC). However, most existing approaches focus on a local perspective, extracting knowledge triplets from individual sentences or documents, missing a fusion process to combine the knowledge in a global KG. This work introduces Graphusion, a zero-shot KGC framework from free text. It contains three steps: in Step 1, we extract a list of seed entities using topic modeling to guide the final KG includes the most relevant entities; in Step 2, we conduct candidate triplet extraction using LLMs; in Step 3, we design the novel fusion module that provides a global view of the extracted knowledge, incorporating entity merging, conflict resolution, and novel triplet discovery. Results show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for entity extraction and relation recognition, respectively. Moreover, we showcase how Graphusion could be applied to the Natural Language Processing (NLP) domain and validate it in an educational scenario. Specifically, we introduce TutorQA, a new expert-verified benchmark for QA, comprising six tasks and a total of 1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant improvement on the benchmark, for example, a 9.2% accuracy improvement on sub-graph completion.', 'citationCount': 1, 'influentialCitationCount': 0, 'authors': [{'authorId': '2287835229', 'name': 'Rui Yang'}, {'authorId': '2275630479', 'name': 'Boming Yang'}, {'authorId': '14128921', 'name': 'Aosong Feng'}, {'authorId': '2284983795', 'name': 'Sixun Ouyang'}, {'authorId': '2285108151', 'name': 'Moritz Blum'}, {'authorId': '2106009217', 'name': 'Tianwei She'}, {'authorId': '2285289624', 'name': 'Yuang Jiang'}, {'authorId': '2281746065', 'name': 'Freddy Lécué'}, {'authorId': '2285824559', 'name': 'Jinghui Lu'}, {'authorId': '2275053812', 'name': 'Irene Li'}], 'publicationDate': '2024-10-23', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['In contrast, our work focuses on shifting from a local perspective to a global one, aiming to generate a more comprehensive KG. Approaches Approaches such as GraphRAG [8] which uses graph indexing and community detection to generate query-focused summaries, effectively answer global questions.', 'The recent success of GraphRAG [8] highlights the value of leveraging a global KG for query-based summarization with the help of large language models (LLMs) [1].'], 'sim_socre': 0.7220910325798451}\n",
      "{'title': 'Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency', 'abstract': 'Knowledge graphs (KGs) generated by large language models (LLMs) are becoming increasingly valuable for Retrieval-Augmented Generation (RAG) applications that require knowledge-intensive reasoning. However, existing KG extraction methods predominantly rely on prompt-based approaches, which are inefficient for processing large-scale corpora. These approaches often suffer from information loss, particularly with long documents, due to the lack of specialized design for KG construction. Additionally, there is a gap in evaluation datasets and methodologies for ontology-free KG construction. To overcome these limitations, we propose SynthKG, a multi-step, document-level ontology-free KG synthesis workflow based on LLMs. By fine-tuning a smaller LLM on the synthesized document-KG pairs, we streamline the multi-step process into a single-step KG generation approach called Distill-SynthKG, substantially reducing the number of LLM inference calls. Furthermore, we re-purpose existing question-answering datasets to establish KG evaluation datasets and introduce new evaluation metrics. Using KGs produced by Distill-SynthKG, we also design a novel graph-based retrieval framework for RAG. Experimental results demonstrate that Distill-SynthKG not only surpasses all baseline models in KG quality -- including models up to eight times larger -- but also consistently excels in retrieval and question-answering tasks. Our proposed graph retrieval framework also outperforms all KG-retrieval methods across multiple benchmark datasets. We release the SynthKG dataset and Distill-SynthKG model publicly to support further research and development.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '3466801', 'name': 'Prafulla Kumar Choubey'}, {'authorId': '2263587631', 'name': 'Xin Su'}, {'authorId': '2309218122', 'name': 'Man Luo'}, {'authorId': '2324805044', 'name': 'Xiangyu Peng'}, {'authorId': '2266753302', 'name': 'Caiming Xiong'}, {'authorId': '2249909984', 'name': 'Tiep Le'}, {'authorId': '1992685069', 'name': 'Shachar Rosenman'}, {'authorId': '2309247409', 'name': 'Vasudev Lal'}, {'authorId': '2122258484', 'name': 'P. Mùi'}, {'authorId': '2327047843', 'name': 'Ricky Ho'}, {'authorId': '2263959561', 'name': 'Phillip Howard'}, {'authorId': '2267031643', 'name': 'Chien-Sheng Wu'}], 'publicationDate': '2024-10-22', 'year': 2024, 'isInfluential': True, 'intents': ['background', 'methodology'], 'contexts': ['Directly inputting long texts into an LLM has been shown to result in information loss (Edge et al., 2024).', 'Recent works (Edge et al., 2024; Gutiérrez et al., 2024) have begun exploring the use of LLMs to automate the construction of KGs, which then serve as knowledge sources for specific tasks such as question answering or building intelligent agentic frameworks.', '…(KG) augmented RAG methods have demonstrated strong potential, offering several advantages such as effective corpus-level information summarization (Edge et al., 2024), improved reasoning capabilities (Gutiérrez et al., 2024; Li et al., 2024), and accurate modeling of historical customer issue…', 'For instance, GraphRAG (Edge et al., 2024) shows the advantages of using KGs over a text corpus for answering global queries that require summarizing information from multiple documents.', 'Having LLMs process entire documents, particularly long texts, has been shown to potentially lead to issues such as information loss (Edge et al., 2024).', 'Following the paradigm of Edge et al. (2024) and Gutiérrez et al. (2024), we first prompt the LLM to extract all entities and their corresponding types from each text chunk, as shown in Step 3 of Figure 1.'], 'sim_socre': 0.7761712917863077}\n",
      "{'title': 'From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs', 'abstract': \"Recent advancements in large language models have significantly improved their context windows, yet challenges in effective long-term memory management remain. We introduce MemTree, an algorithm that leverages a dynamic, tree-structured memory representation to optimize the organization, retrieval, and integration of information, akin to human cognitive schemas. MemTree organizes memory hierarchically, with each node encapsulating aggregated textual content, corresponding semantic embeddings, and varying abstraction levels across the tree's depths. Our algorithm dynamically adapts this memory structure by computing and comparing semantic embeddings of new and existing information to enrich the model's context-awareness. This approach allows MemTree to handle complex reasoning and extended interactions more effectively than traditional memory augmentation methods, which often rely on flat lookup tables. Evaluations on benchmarks for multi-turn dialogue understanding and document question answering show that MemTree significantly enhances performance in scenarios that demand structured memory management.\", 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2326834839', 'name': 'Alireza Rezazadeh'}, {'authorId': '2326941918', 'name': 'Zichao Li'}, {'authorId': '2306480290', 'name': 'Wei Wei'}, {'authorId': '2306754738', 'name': 'Yujia Bao'}], 'publicationDate': '2024-10-17', 'year': 2024, 'isInfluential': True, 'intents': ['background', 'methodology'], 'contexts': ['• GraphRAG : Edge et al. (2024) introduces a graph-based indexing approach designed to improve query-focused summarization and extract global insights from large text corpora.', 'GraphRAG (Edge et al., 2024) constructs a knowledge graph from LLM-extracted entities and relations, partitioning it into modular communities that are independently summarized and combined via a map-reduce framework.', 'In contrast, RAPTOR and GraphRAG focus on establishing structured relationships through hierarchical clustering or community detection in a RAG setup, where updating the memory post-index construction is either impossible or costly.', 'Like RAPTOR, GraphRAG assumes access to the entire corpus and applies the Leiden algorithm to identify community structures within the document graph.', 'In multi-document tasks, MemTree not only surpasses online methods but also approaches the performance of offline models, particularly outperforming GraphRAG (Edge et al., 2024).', 'Offline RAG methods such as RAPTOR and GraphRAG, designed for handling knowledge retrieval over longer contexts, achieve lower accuracies of 59.0% and 62.8%, respectively.', 'However, while MemTree expands its memory top-down to allow for efficient, online updates, GraphRAG generates community summaries in a bottom-up fashion, which is less suited for real-time adaptability.'], 'sim_socre': 0.621518352423339}\n",
      "{'title': 'AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data', 'abstract': 'Large Language Models~(LLMs) have demonstrated capabilities across various applications but face challenges such as hallucination, limited reasoning abilities, and factual inconsistencies, especially when tackling complex, domain-specific tasks like question answering~(QA). While Knowledge Graphs~(KGs) have been shown to help mitigate these issues, research on the integration of LLMs with background KGs remains limited. In particular, user accessibility and the flexibility of the underlying KG have not been thoroughly explored. We introduce AGENTiGraph (Adaptive Generative ENgine for Task-based Interaction and Graphical Representation), a platform for knowledge management through natural language interaction. It integrates knowledge extraction, integration, and real-time visualization. AGENTiGraph employs a multi-agent architecture to dynamically interpret user intents, manage tasks, and integrate new knowledge, ensuring adaptability to evolving user requirements and data contexts. Our approach demonstrates superior performance in knowledge graph interactions, particularly for complex domain-specific tasks. Experimental results on a dataset of 3,500 test cases show AGENTiGraph significantly outperforms state-of-the-art zero-shot baselines, achieving 95.12\\\\% accuracy in task classification and 90.45\\\\% success rate in task execution. User studies corroborate its effectiveness in real-world scenarios. To showcase versatility, we extended AGENTiGraph to legislation and healthcare domains, constructing specialized KGs capable of answering complex queries in legal and medical contexts.', 'citationCount': 1, 'influentialCitationCount': 0, 'authors': [{'authorId': '2326046045', 'name': 'Xinjie Zhao'}, {'authorId': '2285108151', 'name': 'Moritz Blum'}, {'authorId': '2287835229', 'name': 'Rui Yang'}, {'authorId': '2275630479', 'name': 'Boming Yang'}, {'authorId': '2255316467', 'name': 'Luis Marquez-Carpintero'}, {'authorId': '2325953216', 'name': \"M'onica Pina-Navarro\"}, {'authorId': '2326071429', 'name': 'Tony Wang'}, {'authorId': '2326106964', 'name': 'Xin Li'}, {'authorId': '2326063945', 'name': 'Huitao Li'}, {'authorId': '2326109980', 'name': 'Yanran Fu'}, {'authorId': '2326483937', 'name': 'Rongrong Wang'}, {'authorId': '2325991413', 'name': 'Juntao Zhang'}, {'authorId': '2275053812', 'name': 'Irene Li'}], 'publicationDate': '2024-10-15', 'year': 2024, 'isInfluential': False, 'intents': ['background'], 'contexts': ['This is where Knowledge Graphs (KGs) come into play (Edge et al., 2024; Nickel et al., 2015).'], 'sim_socre': 0.7101654898025604}\n",
      "{'title': 'FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG', 'abstract': \"Retrieval-Augmented Generation (RAG) prevails in Large Language Models. It mainly consists of retrieval and generation. The retrieval modules (a.k.a. retrievers) aim to find useful information used to facilitate the generation modules (a.k.a. generators). As such, generators' performance largely depends on the effectiveness and efficiency of retrievers. However, the widely used retrieval paradigm remains flat. It treats retrieval procedures as a one-off deal with constant granularity. Despite effectiveness, we argue that they suffer from two limitations: (1) flat retrieval exerts a significant burden on one retriever; (2) constant granularity limits the ceiling of retrieval performance. In this work, we propose a progressive retrieval paradigm with coarse-to-fine granularity for RAG, termed FunnelRAG, so as to balance effectiveness and efficiency. Specifically, FunnelRAG establishes a progressive retrieval pipeline by collaborating coarse-to-fine granularity, large-to-small quantity, and low-to-high capacity, which can relieve the burden on one retriever and also promote the ceiling of retrieval performance. Extensive experiments manifest that FunnelRAG achieves comparable retrieval performance while the time overhead is reduced by nearly 40 percent.\", 'citationCount': 3, 'influentialCitationCount': 0, 'authors': [{'authorId': '2326046038', 'name': 'Xinping Zhao'}, {'authorId': '2326297398', 'name': 'Yan Zhong'}, {'authorId': '2265614778', 'name': 'Zetian Sun'}, {'authorId': '2149467818', 'name': 'Xinshuo Hu'}, {'authorId': '2230018369', 'name': 'Zhenyu Liu'}, {'authorId': '2265618386', 'name': 'Dongfang Li'}, {'authorId': '2285172247', 'name': 'Baotian Hu'}, {'authorId': '2258690227', 'name': 'Min Zhang'}], 'publicationDate': '2024-10-14', 'year': 2024, 'isInfluential': False, 'intents': ['background', 'methodology'], 'contexts': ['…Generation (RAG) has been shown highly effective in enhancing Large Language Models (LLMs) (Gao et al., 2023; Shi et al., 2023) and has been widely adopted in the industry, such as Microsoft’s GraphRAG (Edge et al., 2024), Google’s REALM (Guu et al., 2020), and Meta’s RA-DIT (Lin et al., 2024).', 'Retrieval-Augmented Generation (RAG) has been shown highly effective in enhancing Large Language Models (LLMs) (Gao et al., 2023; Shi et al., 2023) and has been widely adopted in the industry, such as Microsoft’s GraphRAG (Edge et al., 2024), Google’s REALM (Guu et al., 2020), and Meta’s RA-DIT (Lin et al., 2024).', '…by RAG’s strong practicality, a wide range of domains have developed specific RAG frameworks to perform their tasks, including computer vision (Xie et al., 2023; Sharifymoghaddam et al., 2024), knowledge graph (Yu et al., 2022; Edge et al., 2024), and speech (Xue et al., 2024; Wang et al., 2024).'], 'sim_socre': 0.71687824781852}\n",
      "{'title': 'Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs', 'abstract': 'Retrieval-augmented generation (RAG) has revitalized Large Language Models (LLMs) by injecting non-parametric factual knowledge. Compared with long-context LLMs, RAG is considered an effective summarization tool in a more concise and lightweight manner, which can interact with LLMs multiple times using diverse queries to get comprehensive responses. However, the LLM-generated historical responses, which contain potentially insightful information, are largely neglected and discarded by existing approaches, leading to suboptimal results. In this paper, we propose \\\\textit{graph of records} (\\\\textbf{GoR}), which leverages historical responses generated by LLMs to enhance RAG for long-context global summarization. Inspired by the \\\\textit{retrieve-then-generate} paradigm of RAG, we construct a graph by establishing an edge between the retrieved text chunks and the corresponding LLM-generated response. To further uncover the intricate correlations between them, GoR further features a \\\\textit{graph neural network} and an elaborately designed \\\\textit{BERTScore}-based objective for self-supervised model training, enabling seamless supervision signal backpropagation between reference summaries and node embeddings. We comprehensively compare GoR with 12 baselines across four long-context summarization datasets, and the results indicate that our proposed method reaches the best performance e.g., 15\\\\%, 8\\\\%, and 19\\\\% improvement over retrievers w.r.t. Rouge-L, Rouge-1, and Rouge-2 on the WCEP dataset). Extensive experiments further demonstrate the effectiveness of GoR. Code is available at https://github.com/ulab-uiuc/GoR', 'citationCount': 2, 'influentialCitationCount': 0, 'authors': [{'authorId': '2326070420', 'name': 'Haozhen Zhang'}, {'authorId': '2300275413', 'name': 'Tao Feng'}, {'authorId': '2261495159', 'name': 'Jiaxuan You'}], 'publicationDate': '2024-10-14', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': [], 'sim_socre': 0.7858446421456243}\n",
      "{'title': 'StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization', 'abstract': 'Retrieval-augmented generation (RAG) is a key means to effectively enhance large language models (LLMs) in many knowledge-based tasks. However, existing RAG methods struggle with knowledge-intensive reasoning tasks, because useful information required to these tasks are badly scattered. This characteristic makes it difficult for existing RAG methods to accurately identify key information and perform global reasoning with such noisy augmentation. In this paper, motivated by the cognitive theories that humans convert raw information into various structured knowledge when tackling knowledge-intensive reasoning, we proposes a new framework, StructRAG, which can identify the optimal structure type for the task at hand, reconstruct original documents into this structured format, and infer answers based on the resulting structure. Extensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance, particularly excelling in challenging scenarios, demonstrating its potential as an effective solution for enhancing LLMs in complex real-world applications.', 'citationCount': 5, 'influentialCitationCount': 1, 'authors': [{'authorId': '2292591497', 'name': 'Zhuoqun Li'}, {'authorId': '49794910', 'name': 'Xuanang Chen'}, {'authorId': '2288351000', 'name': 'Haiyang Yu'}, {'authorId': '2116455765', 'name': 'Hongyu Lin'}, {'authorId': '1831434', 'name': 'Yaojie Lu'}, {'authorId': '2217344770', 'name': 'Qiaoyu Tang'}, {'authorId': '2257407873', 'name': 'Fei Huang'}, {'authorId': '2118233348', 'name': 'Xianpei Han'}, {'authorId': '2110832778', 'name': 'Le Sun'}, {'authorId': '2287833084', 'name': 'Yongbin Li'}], 'publicationDate': '2024-10-11', 'year': 2024, 'isInfluential': True, 'intents': ['result', 'background'], 'contexts': ['Another kind of approach involves extracting entity-relation triples from given text documents based on query requirements to construct graph structures, which are then used for knowledge augmentation (Fang et al., 2024; Edge et al., 2024; Panda et al., 2024).', 'In addition, this paper chooses Podcast Transcripts , which is a query-focused summarization task reported by GraphRAG (Edge et al., 2024).', 'In this section, we report average latency of StructRAG and compare it with the RQ-RAG (Chan et al., 2024) and GraphRAG (Edge et al., 2024).', 'Recently, to assist LLMs in handling complex question-answering tasks, some works introduce graph structures into RAG systems (Edge et al., 2024; Panda et al., 2024; Peng et al., 2024).', '(4) GraphRAG (Edge et al., 2024), which extracts triples (head, relationship, tail) from raw documents and constructs into multi-layered graphs, then uses structured information in graphs to help the generation model answer questions.'], 'sim_socre': 0.775708310724347}\n",
      "{'title': 'Enhancing Large Language Models with Knowledge Graphs for Robust Question Answering', 'abstract': 'In recent years, large language models (LLMs) have shown rapid development, becoming one of the most popular topics in the field of artificial intelligence. LLMs have demonstrated powerful generalization and learning capabilities, and their performance on various language tasks has been remarkable. Despite their successes, LLMs face significant challenges, particularly in domain-specific tasks that require structured knowledge, often leading to issues such as hallucinations. To mitigate these challenges, we propose a novel system, SynaptiQA, which integrates LLMs with Knowledge Graphs (KGs) to answer more questions about knowledge. Our approach leverages the generative capabilities of LLMs to create and optimize KG queries, thereby improving the accuracy and contextual relevance of responses. Experimental results in an industrial data set demonstrate that SynaptiQA outperforms baseline models and naive retrieval-augmented generation (RAG) systems, demonstrating improved accuracy and reduced hallucinations. This integration of KGs with LLMs paves the way for more reliable and interpretable domain-specific question answering systems.', 'citationCount': 0, 'influentialCitationCount': 0, 'authors': [{'authorId': '2279657000', 'name': 'Zhui Zhu'}, {'authorId': '2308470457', 'name': 'Guangpeng Qi'}, {'authorId': '2303654688', 'name': 'Guangyong Shang'}, {'authorId': '2333857119', 'name': 'Qingfeng He'}, {'authorId': '2336917426', 'name': 'Weichen Zhang'}, {'authorId': '2333287928', 'name': 'Ningbo Li'}, {'authorId': '2333373033', 'name': 'Yunzhi Chen'}, {'authorId': '2333372865', 'name': 'Lijun Hu'}, {'authorId': '2336920267', 'name': 'Wenqiang Zhang'}, {'authorId': '2261559414', 'name': 'Fan Dang'}], 'publicationDate': '2024-10-10', 'year': 2024, 'isInfluential': False, 'intents': [], 'contexts': ['Additionally, the effectiveness of the RAG methods heavily relies on the segmentation of the document chunks, as incorrect or inappropriate document segmentation can significantly impact its effectiveness [9].', 'However, when data is processed and stored as vectors, the relationship between the context is often lost, and relationships between data points can become particularly ambiguous [9].'], 'sim_socre': 0.7223706916263163}\n"
     ]
    }
   ],
   "source": [
    "paper_authors_ids = [x.get('authorId') for x in paper_metadata.get('authors', [])]\n",
    "for item in citedby_metadata_lst:\n",
    "    cited_authors_ids = [x.get('authorId') for x in item.get('authors', [])]\n",
    "    if (item.get('sim_socre', 0) > 0.7 \n",
    "        or (item.get('isInfluential', False) == True and item.get('sim_socre', 0) > 0.5)\n",
    "        or (len(item.get('contexts', [])) > 3 and item.get('sim_socre', 0) > 0.5)\n",
    "        or (len(set(paper_authors_ids) & set(cited_authors_ids)) > 0 and item.get('sim_socre', 0) > 0.5)):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommended Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Paper Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send to mineru for process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apis.mineru_tool import MinerUKit\n",
    "\n",
    "mineru = MinerUKit(api_key=os.getenv('MINERU_API_KEY_1'))\n",
    "res = mineru.batch_process_files(pdf_files=[pdf_path], if_ocr=False, lang='en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if res.status_code == 200:\n",
    "    batch_id = res.json().get('data', {}).get('batch_id')\n",
    "    print(batch_id)\n",
    "    if batch_id:\n",
    "        mineru.monitor_batch_status(batch_id=batch_id, save_path=data_path, interval=10, max_retries=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For main paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outline\n",
    "from pdf_process.pdf_outline_gen import PDFOutline\n",
    "\n",
    "outline = PDFOutline(pdf_path=pdf_path)\n",
    "toc_1 = outline.toc_extraction()\n",
    "toc_1_rvsd = outline.identify_toc_appendix(toc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post process\n",
    "file_name = os.path.basename(pdf_path)\n",
    "file_name_nosuffix = file_name.rsplit('.', 1)[0] \n",
    "processed_file_path = os.path.join(data_path, file_name_nosuffix)\n",
    "\n",
    "md_file = os.path.join(processed_file_path, \"full.md\")\n",
    "content_json_file = os.path.join(processed_file_path, \"content_list.json\")\n",
    "\n",
    "import json\n",
    "with open(content_json_file) as json_data:\n",
    "    content_json = json.load(json_data)\n",
    "\n",
    "with open(md_file, 'r', encoding='utf-8') as f:\n",
    "    markdown_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_process.pdf_post_process import PDFProcess\n",
    "\n",
    "pdf = PDFProcess(pdf_path=pdf_path, pdf_toc=toc_1_rvsd,pdf_json=content_json)\n",
    "pdf.align_md_toc()\n",
    "pdf.align_content_json()\n",
    "pdf.align_reference_info(reference_metadata)\n",
    "pdf_json_rvsd_path = os.path.join(processed_file_path, \"processed_content_list.json\")\n",
    "\n",
    "with open(pdf_json_rvsd_path, \"w\") as file:\n",
    "    json.dump(pdf.pdf_json, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf segmentation\n",
    "import json\n",
    "\n",
    "pdf_json_rvsd_path = \"/home/jiezi/Code/GitHub/PaperReadThrough/data/2501.04682v1/processed_content_list.json\"\n",
    "with open(pdf_json_rvsd_path, \"r\") as file:\n",
    "    pdf_json_rvsd = json.load(file)\n",
    "\n",
    "# name patterns for image / table / equation names\n",
    "seg = PDFSeg(pdf_json_rvsd)\n",
    "toc_hierachy = seg.get_toc_hierachy()\n",
    "seg_paras = seg.gen_seg_paras(toc_hierachy)\n",
    "seg_paras_rvsd = seg.restore_seg_elements(seg_paras)\n",
    "md_text = seg.gen_md_from_json(pdf_json_rvsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate topics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
