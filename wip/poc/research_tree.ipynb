{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jiezi/Code/GitHub/ResearchRetrospect/wip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "print(parent_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate most important and relevant researches and formalize research tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a recent HippoRAG paper for example. \n",
    "- It rooted in RAG;\n",
    "- Some of the key researchs like GraphRAG should be included;\n",
    "- Better to have related works in llm memory and llm reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 15:11:22,470 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=HippoRAG%3A+Neurobiologically+Inspired+Long-Term+Memory+for+Large+Language+Models&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=3 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4308208fac24626e0c927ee728038aadc4e87266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 15:11:24,606 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/4308208fac24626e0c927ee728038aadc4e87266/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n",
      "2025-03-06 15:11:27,462 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/4308208fac24626e0c927ee728038aadc4e87266/citations?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from apis.semanticscholar_tool import SemanticScholarKit\n",
    "\n",
    "s2 = SemanticScholarKit()\n",
    "s2_metadata = s2.search_paper_by_keywords(query=title, limit=3)\n",
    "\n",
    "paper_s2_id = s2_metadata[0].get('paperId')\n",
    "print(paper_s2_id)\n",
    "\n",
    "citing_metadata = s2.get_semanticscholar_references(paper_id=paper_s2_id, limit=100)\n",
    "print(len(citing_metadata))\n",
    "\n",
    "citedby_metadata = s2.get_semanticscholar_citedby(paper_id=paper_s2_id, limit=100)\n",
    "print(len(citedby_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 15:12:31,373 - INFO - HTTP Request: POST https://api.semanticscholar.org/recommendations/v1/papers/?fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&limit=100 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "paper_recommended_info = s2.find_recommendations(positive_paper_ids=[paper_s2_id])\n",
    "print(len(paper_recommended_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = s2_metadata[0].get('authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_ids = [x.get('authorId') for x in authors if x.get('authorId') is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1666169546', '1406331721', '2022231256', '19168196', '1758652']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author data not ready. Added here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 16:35:56,438 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/author/batch?fields=affiliations%2CauthorId%2CcitationCount%2CexternalIds%2ChIndex%2Chomepage%2Cname%2CpaperCount%2Cpapers%2Cpapers.abstract%2Cpapers.authors%2Cpapers.citationCount%2Cpapers.corpusId%2Cpapers.externalIds%2Cpapers.fieldsOfStudy%2Cpapers.influentialCitationCount%2Cpapers.isOpenAccess%2Cpapers.journal%2Cpapers.openAccessPdf%2Cpapers.paperId%2Cpapers.publicationDate%2Cpapers.publicationTypes%2Cpapers.publicationVenue%2Cpapers.referenceCount%2Cpapers.s2FieldsOfStudy%2Cpapers.title%2Cpapers.url%2Cpapers.venue%2Cpapers.year%2Curl \"HTTP/1.1 429 \"\n",
      "2025-03-06 16:36:27,804 - INFO - HTTP Request: POST https://api.semanticscholar.org/graph/v1/author/batch?fields=affiliations%2CauthorId%2CcitationCount%2CexternalIds%2ChIndex%2Chomepage%2Cname%2CpaperCount%2Cpapers%2Cpapers.abstract%2Cpapers.authors%2Cpapers.citationCount%2Cpapers.corpusId%2Cpapers.externalIds%2Cpapers.fieldsOfStudy%2Cpapers.influentialCitationCount%2Cpapers.isOpenAccess%2Cpapers.journal%2Cpapers.openAccessPdf%2Cpapers.paperId%2Cpapers.publicationDate%2Cpapers.publicationTypes%2Cpapers.publicationVenue%2Cpapers.referenceCount%2Cpapers.s2FieldsOfStudy%2Cpapers.title%2Cpapers.url%2Cpapers.venue%2Cpapers.year%2Curl \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "sch = SemanticScholar()\n",
    "authors_metadata = sch.get_authors(author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['authorId', 'externalIds', 'url', 'name', 'affiliations', 'homepage', 'paperCount', 'citationCount', 'hIndex', 'papers'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_metadata[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authorId': '1666169546', 'externalIds': {}, 'url': 'https://www.semanticscholar.org/author/1666169546', 'name': 'Bernal Jimenez Gutierrez', 'affiliations': [], 'homepage': None, 'paperCount': 7, 'citationCount': 304, 'hIndex': 5, 'papers': [{'paperId': '4308208fac24626e0c927ee728038aadc4e87266', 'externalIds': {'DBLP': 'journals/corr/abs-2405-14831', 'ArXiv': '2405.14831', 'DOI': '10.48550/arXiv.2405.14831', 'CorpusId': 269982289}, 'corpusId': 269982289, 'publicationVenue': {'id': 'd9720b90-d60b-48bc-9df8-87a30b9a60dd', 'name': 'Neural Information Processing Systems', 'type': 'conference', 'alternate_names': ['Neural Inf Process Syst', 'NeurIPS', 'NIPS'], 'url': 'http://neurips.cc/'}, 'url': 'https://www.semanticscholar.org/paper/4308208fac24626e0c927ee728038aadc4e87266', 'title': 'HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models', 'abstract': 'In order to thrive in hostile and ever-changing natural environments, mammalian brains evolved to store large amounts of knowledge about the world and continually integrate new information while avoiding catastrophic forgetting. Despite the impressive accomplishments, large language models (LLMs), even with retrieval-augmented generation (RAG), still struggle to efficiently and effectively integrate a large amount of new experiences after pre-training. In this work, we introduce HippoRAG, a novel retrieval framework inspired by the hippocampal indexing theory of human long-term memory to enable deeper and more efficient knowledge integration over new experiences. HippoRAG synergistically orchestrates LLMs, knowledge graphs, and the Personalized PageRank algorithm to mimic the different roles of neocortex and hippocampus in human memory. We compare HippoRAG with existing RAG methods on multi-hop question answering and show that our method outperforms the state-of-the-art methods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves comparable or better performance than iterative retrieval like IRCoT while being 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into IRCoT brings further substantial gains. Finally, we show that our method can tackle new types of scenarios that are out of reach of existing methods. Code and data are available at https://github.com/OSU-NLP-Group/HippoRAG.', 'venue': 'Neural Information Processing Systems', 'year': 2024, 'referenceCount': 76, 'citationCount': 16, 'influentialCitationCount': 3, 'isOpenAccess': False, 'openAccessPdf': None, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle'], 'publicationDate': '2024-05-23', 'journal': {'volume': 'abs/2405.14831', 'name': 'ArXiv'}, 'authors': [{'authorId': '1666169546', 'name': 'Bernal Jimenez Gutierrez'}, {'authorId': '1406331721', 'name': 'Yiheng Shu'}, {'authorId': '2022231256', 'name': 'Yu Gu'}, {'authorId': '19168196', 'name': 'Michihiro Yasunaga'}, {'authorId': '1758652', 'name': 'Yu Su'}]}, {'paperId': '30f36f68265823c7f9945f902451fe0b1fac790b', 'externalIds': {'ACL': '2023.bionlp-1.32', 'ArXiv': '2306.17649', 'DBLP': 'journals/corr/abs-2306-17649', 'DOI': '10.48550/arXiv.2306.17649', 'CorpusId': 259308931}, 'corpusId': 259308931, 'publicationVenue': {'id': '3afb600a-49ad-40aa-858c-081def027584', 'name': 'Workshop on Biomedical Natural Language Processing', 'type': 'conference', 'alternate_names': ['BioNLP', 'Workshop Biomed Nat Lang Process']}, 'url': 'https://www.semanticscholar.org/paper/30f36f68265823c7f9945f902451fe0b1fac790b', 'title': 'Biomedical Language Models are Robust to Sub-optimal Tokenization', 'abstract': 'As opposed to general English, many concepts in biomedical terminology have been designed in recent history by biomedical professionals with the goal of being precise and concise. This is often achieved by concatenating meaningful biomedical morphemes to create new semantic units. Nevertheless, most modern biomedical language models (LMs) are pre-trained using standard domain-specific tokenizers derived from large scale biomedical corpus statistics without explicitly leveraging the agglutinating nature of biomedical language. In this work, we first find that standard open-domain and biomedical tokenizers are largely unable to segment biomedical terms into meaningful components. Therefore, we hypothesize that using a tokenizer which segments biomedical terminology more accurately would enable biomedical LMs to improve their performance on downstream biomedical NLP tasks, especially ones which involve biomedical terms directly such as named entity recognition (NER) and entity linking. Surprisingly, we find that pre-training a biomedical LM using a more accurate biomedical tokenizer does not improve the entity representation quality of a language model as measured by several intrinsic and extrinsic measures such as masked language modeling prediction (MLM) accuracy as well as NER and entity linking performance. These quantitative findings, along with a case study which explores entity representation quality more directly, suggest that the biomedical pre-training process is quite robust to instances of sub-optimal tokenization.', 'venue': 'Workshop on Biomedical Natural Language Processing', 'year': 2023, 'referenceCount': 49, 'citationCount': 4, 'influentialCitationCount': 0, 'isOpenAccess': True, 'openAccessPdf': {'url': 'https://arxiv.org/pdf/2306.17649', 'status': None}, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle'], 'publicationDate': '2023-06-30', 'journal': {'volume': 'abs/2306.17649', 'name': 'ArXiv'}, 'authors': [{'authorId': '1666169546', 'name': 'Bernal Jimenez Gutierrez'}, {'authorId': '1515546612', 'name': 'Huan Sun'}, {'authorId': '1758652', 'name': 'Yu Su'}]}, {'paperId': 'e01c2a01d54365c8833b816de8ef39a752ffa9b0', 'externalIds': {'DBLP': 'conf/acl/ZhangG023', 'ArXiv': '2305.11159', 'DOI': '10.48550/arXiv.2305.11159', 'CorpusId': 258762464}, 'corpusId': 258762464, 'publicationVenue': {'id': '1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44', 'name': 'Annual Meeting of the Association for Computational Linguistics', 'type': 'conference', 'alternate_names': ['Annu Meet Assoc Comput Linguistics', 'Meeting of the Association for Computational Linguistics', 'ACL', 'Meet Assoc Comput Linguistics'], 'url': 'https://www.aclweb.org/anthology/venues/acl/'}, 'url': 'https://www.semanticscholar.org/paper/e01c2a01d54365c8833b816de8ef39a752ffa9b0', 'title': 'Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors', 'abstract': \"Recent work has shown that fine-tuning large language models (LLMs) on large-scale instruction-following datasets substantially improves their performance on a wide range of NLP tasks, especially in the zero-shot setting. However, even advanced instruction-tuned LLMs still fail to outperform small LMs on relation extraction (RE), a fundamental information extraction task. We hypothesize that instruction-tuning has been unable to elicit strong RE capabilities in LLMs due to RE's low incidence in instruction-tuning datasets, making up less than 1% of all tasks (Wang et al., 2022). To address this limitation, we propose QA4RE, a framework that aligns RE with question answering (QA), a predominant task in instruction-tuning datasets. Comprehensive zero-shot RE experiments over four datasets with two series of instruction-tuned LLMs (six LLMs in total) demonstrate that our QA4RE framework consistently improves LLM performance, strongly verifying our hypothesis and enabling LLMs to outperform strong zero-shot baselines by a large margin. Additionally, we provide thorough experiments and discussions to show the robustness, few-shot effectiveness, and strong transferability of our QA4RE framework. This work illustrates a promising way of adapting LLMs to challenging and underrepresented tasks by aligning these tasks with more common instruction-tuning tasks like QA.\", 'venue': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2023, 'referenceCount': 45, 'citationCount': 63, 'influentialCitationCount': 8, 'isOpenAccess': True, 'openAccessPdf': {'url': 'http://arxiv.org/pdf/2305.11159', 'status': None}, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Conference'], 'publicationDate': '2023-05-18', 'journal': {'volume': 'abs/2305.11159', 'name': 'ArXiv'}, 'authors': [{'authorId': '145086492', 'name': 'Kai Zhang'}, {'authorId': '1666169546', 'name': 'Bernal Jimenez Gutierrez'}, {'authorId': '1758652', 'name': 'Yu Su'}]}, {'paperId': 'cfc12c38a4d848ff3c4225488a2c72e7d4300f4b', 'externalIds': {'DBLP': 'journals/corr/abs-2203-08410', 'ArXiv': '2203.08410', 'DOI': '10.48550/arXiv.2203.08410', 'CorpusId': 247475981}, 'corpusId': 247475981, 'publicationVenue': {'id': '41bf9ed3-85b3-4c90-b015-150e31690253', 'name': 'Conference on Empirical Methods in Natural Language Processing', 'type': 'conference', 'alternate_names': ['Empir Method Nat Lang Process', 'Empirical Methods in Natural Language Processing', 'Conf Empir Method Nat Lang Process', 'EMNLP'], 'url': 'https://www.aclweb.org/portal/emnlp'}, 'url': 'https://www.semanticscholar.org/paper/cfc12c38a4d848ff3c4225488a2c72e7d4300f4b', 'title': 'Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again', 'abstract': \"The strong few-shot in-context learning capability of large pre-trained language models (PLMs) such as GPT-3 is highly appealing for application domains such as biomedicine, which feature high and diverse demands of language technologies but also high data annotation costs. In this paper, we present the first systematic and comprehensive study to compare the few-shot performance of GPT-3 in-context learning with fine-tuning smaller (i.e., BERT-sized) PLMs on two highly representative biomedical information extraction tasks, named entity recognition and relation extraction. We follow the true few-shot setting to avoid overestimating models' few-shot performance by model selection over a large validation set. We also optimize GPT-3's performance with known techniques such as contextual calibration and dynamic in-context example retrieval. However, our results show that GPT-3 still significantly underperforms compared to simply fine-tuning a smaller PLM. In addition, GPT-3 in-context learning also yields smaller gains in accuracy when more training data becomes available. Our in-depth analyses further reveal issues of the in-context learning setting that may be detrimental to information extraction tasks in general. Given the high cost of experimenting with GPT-3, we hope our study provides guidance for biomedical researchers and practitioners towards more promising directions such as fine-tuning small PLMs.\", 'venue': 'Conference on Empirical Methods in Natural Language Processing', 'year': 2022, 'referenceCount': 48, 'citationCount': 140, 'influentialCitationCount': 10, 'isOpenAccess': True, 'openAccessPdf': {'url': 'https://arxiv.org/pdf/2203.08410', 'status': None}, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Conference'], 'publicationDate': '2022-03-16', 'journal': {'pages': '4497-4512'}, 'authors': [{'authorId': '1666169546', 'name': 'Bernal Jimenez Gutierrez'}, {'authorId': '2158996561', 'name': 'Nikolas McNeal'}, {'authorId': '2158995823', 'name': 'Clay Washington'}, {'authorId': '2146309102', 'name': 'You Chen'}, {'authorId': '2159083875', 'name': 'Lang Li'}, {'authorId': '1515546612', 'name': 'Huan Sun'}, {'authorId': '1758652', 'name': 'Yu Su'}]}, {'paperId': '606aa277797e2f6af49a2670480580564705fdee', 'externalIds': {'DBLP': 'conf/bibm/ManiYGHLS20', 'DOI': '10.1109/BIBM49941.2020.9313496', 'CorpusId': 230333509}, 'corpusId': 230333509, 'publicationVenue': {'id': '6363ebc9-706a-4203-b804-148cbf8810ce', 'name': 'IEEE International Conference on Bioinformatics and Biomedicine', 'type': 'conference', 'alternate_names': ['Bioinform Biomed', 'BIBM', 'IEEE Int Conf Bioinform Biomed', 'Bioinformatics and Biomedicine'], 'url': 'http://www.wikicfp.com/cfp/program?id=283'}, 'url': 'https://www.semanticscholar.org/paper/606aa277797e2f6af49a2670480580564705fdee', 'title': 'Clinical Phrase Mining with Language Models', 'abstract': 'A vast amount of vital clinical data is available within unstructured texts such as discharge summaries and procedure notes in Electronic Medical Records (EMRs). Automatically transforming such unstructured data into structured units is crucial for effective data analysis in the field of clinical informatics. Recognizing phrases that reveal important medical information in a concise and thorough manner is a fundamental step in this process. Existing systems that are built for opendomain texts are designed to detect mostly non-medical phrases, while tools designed specifically for extracting concepts from clinical texts are not scalable to large corpora and often leave out essential context surrounding those detected clinical concepts. We address these issues by proposing a framework, CliniPhrase, which adapts domain-specific deep neural network based language models (such as ClinicalBERT) to effectively and efficiently extract high-quality phrases from clinical documents with a limited amount of training data. Experimental results on the MIMIC-III dataset show that our method can outperform the current state-of-the-art techniques by up to 18% in terms of F1 measure while being very efficient (up to 48 times faster).11Our source code, pre-trained models and documentations are available online at: https://github.com/kaushikmani/PhraseMiningLM', 'venue': 'IEEE International Conference on Bioinformatics and Biomedicine', 'year': 2020, 'referenceCount': 46, 'citationCount': 4, 'influentialCitationCount': 0, 'isOpenAccess': False, 'openAccessPdf': None, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Conference'], 'publicationDate': '2020-12-16', 'journal': {'pages': '1087-1090', 'name': '2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)'}, 'authors': [{'authorId': '2046897370', 'name': 'Kaushik Mani'}, {'authorId': '2144065082', 'name': 'Xiang Yue'}, {'authorId': '1666169546', 'name': 'Bernal Jimenez Gutierrez'}, {'authorId': '1944286131', 'name': 'Yungui Huang'}, {'authorId': '2145200118', 'name': 'Simon M. Lin'}, {'authorId': '1515546612', 'name': 'Huan Sun'}]}, {'paperId': '85bb1317013141d5e5f41d18376cd7257c46264a', 'externalIds': {'MAG': '3037675529', 'ACL': '2020.nlpcovid19-acl.3', 'DBLP': 'journals/corr/abs-2006-13816', 'ArXiv': '2006.13816', 'CorpusId': 220041678}, 'corpusId': 220041678, 'publicationVenue': None, 'url': 'https://www.semanticscholar.org/paper/85bb1317013141d5e5f41d18376cd7257c46264a', 'title': 'Document Classification for COVID-19 Literature', 'abstract': 'The global pandemic has made it more important than ever to quickly and accurately retrieve relevant scientific literature for effective consumption by researchers in a wide range of fields. We provide an analysis of several multi-label document classification models on the LitCovid dataset. We find that pre-trained language models outperform other models in both low and high data regimes, achieving a maximum F1 score of around 86%. We note that even the highest performing models still struggle with label correlation, distraction from introductory text and CORD-19 generalization. Both data and code are available on GitHub.', 'venue': 'NLPCOVID19', 'year': 2020, 'referenceCount': 19, 'citationCount': 31, 'influentialCitationCount': 3, 'isOpenAccess': False, 'openAccessPdf': None, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle'], 'publicationDate': '2020-06-15', 'journal': {'volume': 'abs/2006.13816', 'name': 'ArXiv'}, 'authors': [{'authorId': '1666169546', 'name': 'Bernal Jimenez Gutierrez'}, {'authorId': '3361117', 'name': 'Juncheng Zeng'}, {'authorId': '144934143', 'name': 'Dongdong Zhang'}, {'authorId': '2154286366', 'name': 'Ping Zhang'}, {'authorId': '1758652', 'name': 'Yu Su'}]}, {'paperId': 'ec51c9be66fef4321e45a4904c7368287ec0321c', 'externalIds': {'DBLP': 'conf/acl/YueGS20', 'ArXiv': '2005.00574', 'ACL': '2020.acl-main.410', 'MAG': '3035129496', 'DOI': '10.18653/v1/2020.acl-main.410', 'CorpusId': 218486765}, 'corpusId': 218486765, 'publicationVenue': {'id': '1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44', 'name': 'Annual Meeting of the Association for Computational Linguistics', 'type': 'conference', 'alternate_names': ['Annu Meet Assoc Comput Linguistics', 'Meeting of the Association for Computational Linguistics', 'ACL', 'Meet Assoc Comput Linguistics'], 'url': 'https://www.aclweb.org/anthology/venues/acl/'}, 'url': 'https://www.semanticscholar.org/paper/ec51c9be66fef4321e45a4904c7368287ec0321c', 'title': 'Clinical Reading Comprehension: A Thorough Analysis of the emrQA Dataset', 'abstract': 'Machine reading comprehension has made great progress in recent years owing to large-scale annotated datasets. In the clinical domain, however, creating such datasets is quite difficult due to the domain expertise required for annotation. Recently, Pampari et al. (EMNLP’18) tackled this issue by using expert-annotated question templates and existing i2b2 annotations to create emrQA, the first large-scale dataset for question answering (QA) based on clinical notes. In this paper, we provide an in-depth analysis of this dataset and the clinical reading comprehension (CliniRC) task. From our qualitative analysis, we find that (i) emrQA answers are often incomplete, and (ii) emrQA questions are often answerable without using domain knowledge. From our quantitative experiments, surprising results include that (iii) using a small sampled subset (5%-20%), we can obtain roughly equal performance compared to the model trained on the entire dataset, (iv) this performance is close to human expert’s performance, and (v) BERT models do not beat the best performing base model. Following our analysis of the emrQA, we further explore two desired aspects of CliniRC systems: the ability to utilize clinical domain knowledge and to generalize to unseen questions and contexts. We argue that both should be considered when creating future datasets.', 'venue': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2020, 'referenceCount': 51, 'citationCount': 47, 'influentialCitationCount': 8, 'isOpenAccess': True, 'openAccessPdf': {'url': 'https://www.aclweb.org/anthology/2020.acl-main.410.pdf', 'status': None}, 'fieldsOfStudy': ['Computer Science'], 's2FieldsOfStudy': [{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Medicine', 'source': 's2-fos-model'}], 'publicationTypes': ['JournalArticle', 'Conference'], 'publicationDate': '2020-05-01', 'journal': {'volume': 'abs/2005.00574', 'name': 'ArXiv'}, 'authors': [{'authorId': '145548079', 'name': 'Xiang Yue'}, {'authorId': '1666169546', 'name': 'Bernal Jimenez Gutierrez'}, {'authorId': '1515546612', 'name': 'Huan Sun'}]}]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_metadata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_metadata[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords and Topics Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = s2_metadata[0].get('title')\n",
    "abstract = s2_metadata[0].get('abstract')\n",
    "authors = s2_metadata[0].get('authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In order to thrive in hostile and ever-changing natural environments, mammalian brains evolved to store large amounts of knowledge about the world and continually integrate new information while avoiding catastrophic forgetting. Despite the impressive accomplishments, large language models (LLMs), even with retrieval-augmented generation (RAG), still struggle to efficiently and effectively integrate a large amount of new experiences after pre-training. In this work, we introduce HippoRAG, a novel retrieval framework inspired by the hippocampal indexing theory of human long-term memory to enable deeper and more efficient knowledge integration over new experiences. HippoRAG synergistically orchestrates LLMs, knowledge graphs, and the Personalized PageRank algorithm to mimic the different roles of neocortex and hippocampus in human memory. We compare HippoRAG with existing RAG methods on multi-hop question answering and show that our method outperforms the state-of-the-art methods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves comparable or better performance than iterative retrieval like IRCoT while being 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into IRCoT brings further substantial gains. Finally, we show that our method can tackle new types of scenarios that are out of reach of existing methods. Code and data are available at https://github.com/OSU-NLP-Group/HippoRAG.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = \", \".join(s2_metadata[0].get('fieldsOfStudy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_topics_example = {\n",
    "    \"field_of_study\": [\"Political Science\", \"Social Media Studies\", \"Communication Studies\", \"Sociology, Digital Culture\"],\n",
    "    \"keywords_and_topics\": [\"social media usage\", \"political polarization\", \"mixed-methods approach\", \"semi-structured interviews\"],\n",
    "    \"tags\": [\"online behavior\", \"echo chambers\", \"survey methodology\", \"young adults\", \"political communication\", \"digital ethnography\", \"ideology\"],\n",
    "}\n",
    "\n",
    "keywords_topics_prompt = \"\"\"You are a sophisticated academic scholar with expertise in {domain}. \n",
    "You are renowned for your ability to quickly grasp the core concepts of research papers and expertly categorize and tag information for optimal organization and retrieval.\n",
    "\n",
    "## TASK\n",
    "When presented with title and abstraction of a research paper, you will meticulously analyze its content and provide the following:\n",
    "- field_of_study: Propose 2-4 detailed academic fields that this research would logically fall under. Consider the interdisciplinary nature of the paragraph as well.\n",
    "- keywords_and_topics: Identify 3-5 key terms, phrases or topics that accurately capture the specific subject matter and central ideas discussed within the paragraph. These keywords should be highly relevant and representative within the specific research area.\n",
    "- tags: Suggest 3-5 concise tags that could be used to further refine the indexing and searchability of the paragraph. These tags might include specific methodologies, theories, named entities, or emerging concepts mentioned within the text. They should be specific enough to differentiate the content from the broader categories.\n",
    "\n",
    "Make sure you output in json with double quotes.\n",
    "\n",
    "## EXAMPLE\n",
    "Here is an example for demonstraction purpose only. Do not use this specific example in your response, it is solely illustrative.\n",
    "\n",
    "Input Paragraph:  \n",
    "<title>  Social media usage heighten political polarization in youth - A quantitative study</title>\n",
    "<abstract>\n",
    "\"This study employed a mixed-methods approach to investigate the impact of social media usage on political polarization among young adults in urban areas. \n",
    "Quantitative data was collected through a survey of 500 participants, while qualitative data was gathered via semi-structured interviews with a subset of 25 participants. \n",
    "The findings suggest a correlation between increased exposure to ideologically homogeneous content online and heightened political polarization.\"\n",
    "</abstract>\n",
    "\n",
    "Hypothetical Output from this Example (Again, illustrative and not to be used in the actual response):\n",
    "```json\n",
    "{example_json}\n",
    "```\n",
    "\n",
    "## INSTRUCTIONS\n",
    "1. Be precise with keywords and topics, avoid overly broad or generic terms.\n",
    "2. Prioritize terms that are most representative and distinctive for the paper.\n",
    "\n",
    "## INPUT\n",
    "Now start analyzing the following paper.\n",
    "<title> {title} </title>\n",
    "<abstract>\n",
    "{abstract}\n",
    "</abstract>\n",
    "\n",
    "## OUTPUT\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.llms import llm_gen_w_retry\n",
    "\n",
    "temperature = 0.1\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY_1')\n",
    "gemini_model_name = \"gemini-2.0-flash\"\n",
    "qa_prompt = keywords_topics_prompt.format(\n",
    "    domain = domains,\n",
    "    example_json = keywords_topics_example,\n",
    "    title = title,\n",
    "    abstract = abstract\n",
    ")\n",
    "print(qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 15:39:42,496 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-03-06 15:39:44,713 - INFO - AFC remote call 1 is done.\n"
     ]
    }
   ],
   "source": [
    "keywords_topics_info = llm_gen_w_retry(gemini_api_key, gemini_model_name, qa_prompt, sys_prompt=None, temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from json_repair import repair_json  # https://github.com/mangiucugna/json_repair/\n",
    "\n",
    "keywords_topics_json = json.loads(repair_json(keywords_topics_info))\n",
    "field_of_study = keywords_topics_json.get('field_of_study')\n",
    "keywords_and_topics = keywords_topics_json.get('keywords_and_topics')\n",
    "tags = keywords_topics_json.get('tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['long-term memory',\n",
       " 'large language models (LLMs)',\n",
       " 'retrieval-augmented generation (RAG)',\n",
       " 'hippocampal indexing theory',\n",
       " 'knowledge integration']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_and_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Processing',\n",
       " 'Artificial Intelligence',\n",
       " 'Cognitive Science',\n",
       " 'Machine Learning']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_of_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HippoRAG',\n",
       " 'knowledge graphs',\n",
       " 'Personalized PageRank',\n",
       " 'multi-hop question answering',\n",
       " 'IRCoT',\n",
       " 'catastrophic forgetting']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 15:47:58,210 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-03-06 15:48:01,063 - INFO - AFC remote call 1 is done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some Google Scholar search queries based on the provided paper information:\n",
      "\n",
      "1.  \"hippocampal indexing theory\" AND \"large language models\" AND \"knowledge integration\"\n",
      "2.  \"retrieval-augmented generation\" AND \"long-term memory\" AND \"knowledge graph\" AND \"multi-hop question answering\"\n",
      "3.  \"catastrophic forgetting\" AND \"large language models\" AND \"continual learning\" AND \"neurobiologically inspired\"\n",
      "4.  \"IRCoT\" AND \"retrieval-augmented generation\" AND \"iterative retrieval\" AND \"knowledge integration\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_query_prompt = \"\"\"You are a sophisticated academic scholar and an expert with search engine. \n",
    "Given the following paper related information, could you utilize your knowledge and skills to compose 2-4 search queries?\n",
    "These search queries would be used in Google Scholar to find more related works and literatures.\n",
    "\n",
    "## INPUT\n",
    "Now start analyzing the following paper.\n",
    "<title> {title} </title>\n",
    "\n",
    "<abstract>\n",
    "{abstract}\n",
    "</abstract>\n",
    "\n",
    "<keywords> {keywords} </keywords>\n",
    "\n",
    "<tags> {tags} </tags>\n",
    "\n",
    "<fields> {field_of_study} </fields>\n",
    "\n",
    "## OUTPUT\n",
    "Output your search queries in list format. Do not include anything else.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt = search_query_prompt.format(\n",
    "    title = title,\n",
    "    abstract = abstract,\n",
    "    keywords = \",\".join(keywords_and_topics),\n",
    "    tags = \",\".join(tags),\n",
    "    field_of_study = \",\".join(field_of_study),\n",
    ")\n",
    "\n",
    "queries_info = llm_gen_w_retry(gemini_api_key, gemini_model_name, qa_prompt, sys_prompt=None, temperature=0.6)\n",
    "print(queries_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- The above queries works with Google Scholar and Semantic Scholar.\n",
    "- For Google, best to have an abbreviate name of the paper (baed on title or citedby paper or other sources.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hop Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-hop Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
